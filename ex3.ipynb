{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Astro 528, Lab 7, Exercise 3\n## GPU Computing III:  Custom GPU Kernels\n\nIn this lab exercise, you'll see how to write a GPU kernel using a fairly low-level interface. This assumes that you've successfully gotten GPUs working with Julia from [exercise 1](ex1.ipynb).  Again, students are advised to run the exercises in this lab on ICS-ACI rather than their own system.  \n\nThe ICS-ACI Jupyter notebook server and interactive desktop provided by the ICS-ACI portal are now using interactive notes that include a GPU, and students should be able to run all the code there.  However, the GPUs on the interactive nodes are relatively modest GPUs.  You may want to go ahead and submit ex3.pbs, so that it can queue and run on a CyberLAMP GPU node while you work through this notebook.  Then you can review the output to compare the results and performance of the GPUs on the interactive node to that of the CyberLAMP GPU nodes.  For submitting jobs, you'll use the [command line interface](https://ics.psu.edu/computing-services/ics-aci-user-guide/#05-00-basics-aci-resources) to submit the PBS jobs, following a similar syntax as the [lab's 6 README](https://github.com/PsuAstro528/lab6-start/blob/master/README.md).  \n\n## Setting up\nFirst, we'll make sure that `CUDAHOME` is set, activate the project in the current directory and load packages to be used. Here we assume that you've already instantiated this project during exercise 1."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "if haskey(ENV,\"CUDAHOME\")\n    println(\"The CUDAHOME environment variable has been set to: \",ENV[\"CUDAHOME\"])\nelse\n    println(\"The CUDAHOME environment variable has not been set.  Setting it now...\")\n    ENV[\"CUDAHOME\"] = \"/gpfs/group/ebf11/default/astro528/cuda\"\nend"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "using Pkg\nPkg.activate(\".\")"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "using CUDAnative,CuArrays"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "using BenchmarkTools"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Explicit GPU Kernels\nIn exercise 2, we wrote Julia functions and let the CuArrays and GPUArrays packages work behind the scenes to turn them into GPU kernels for us.\nIn this exercise, we'll write some simple GPU kernels ourselves, in an effort to better understand how GPUs work.\n\nFirst, we'll write a kernel that initializes an CuArray on the GPU (rather than on the CPU) to take on values evenly spaced between a minimum and maximum values.  For starters, we might write the following."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "function init_1d_grid!(out,N::Integer,min=-1,max=1)\n    @assert length(out) == N\n    i = threadIdx().x\n    @inbounds out[i] = min+(max-min)*(i-1)/(N-1)\n    return nothing\nend"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "To be a valid GPU kernel, a julia function needs to:\n- return nothing, \n- protect array operations with `@inbounds`,\n- have no named parameters, \n- all argument types must be isbitstype(T)==true (basically contain no pointers), \n- avoid error handling like exceptions, print messages, or exiting, and\n- not call functions that violated any of the above (effecitvely excluding many common functions).\nSince we normally want it to do something, we typically pass at least one CuArray or CuDeviceArray that the kernel will write its output into.  Since many threads are running the same code at once, there needs to be a way for each thread to know what part of the work it should do.  The `threadIdx()` function provides the x, y and z coordinate of each thread within a block.  In the first version about, the kernel simply writes to the array location given by `threadIdx().x`.  We can launch a GPU kernel using the `@cuda` macro from CUDAnative.  Let's try that and see what happens."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "N = 2^4\ngrid_1d_d = cuzeros(N);\n@cuda init_1d_grid!(grid_1d_d, N) \ngrid_1d_d"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since we didn't specify a number of threads or blocks, it defaulted to launching just one thread and one block.  Next, we'll launch the kernel with 8 threads per block and a single block.  Before running the code a each cell, think about what you expect to happen."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "@cuda threads=8 init_1d_grid!(grid_1d_d, N) \ngrid_1d_d"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since we launched 8 thread, we successfully wrote into the first 8 elements of the out Array.  Typically, we want to write to every element of the output array.  We can't necessarily have the same number of threads and array elements, so we can have each thread loop over array indices, so as to ensure that the full array is reached.  For example, we could tell each thread to write to the array index corresponding to (the x coordinate of) its own thread index and to array indices corresponding to that plus the size of the thread block."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "function init_1d_grid!(out,N::Integer,min=-1,max=1)\n    @assert length(out) == N\n    index = threadIdx().x\n    stride = blockDim().x\n    for i = index:stride:length(out)\n        @inbounds out[i] = min+(max-min)*(i-1)/(N-1)\n    end\n    return nothing\nend"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "@cuda threads=8 init_1d_grid!(grid_1d_d, N) \ngrid_1d_d"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "The code above assumes that there's only one block running.  If there were multiple blocks launched, then we'd want to make sure that different threads down't duplicate work (wasteful) or overwrite each other (dangerous).  The kernel below shows a better way to choose the indicies that the kernel writes to.  Note that it still assumes that the number of threads per block is of the form (N,1,1) and the number of blocks is of the form (M,1,1). You can think of this as using a 1dimensional block and 1-d grid of blocks.  This makes a lot of sense for 1-d arrays, but won't always be the case (e..g, when working with 2-d arrays)."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "function init_1d_grid!(out,N::Integer,min=-1,max=1)\n    @assert length(out) == N\n    index = (blockIdx().x -1)*blockDim().x + threadIdx().x\n    stride = blockDim().x*gridDim().x\n    for i = index:stride:length(out)\n        @inbounds out[i] = min+(max-min)*(i-1)/(N-1)\n    end\n    return nothing\nend"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "@cuda threads=8 init_1d_grid!(grid_1d_d, N) \ngrid_1d_d"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "At this point, our code won't be very fast because we're using only a single block.  As a result our calculations can only be performed by a single multiprocessor on the GPU.  In order to use all of the GPU's computing resources, we need to divide the work into at least as many blocks as there are multiprocessors.  We can also specify the number of blocks when we launch a kernel using the `@cuda` macro as shown below.  We'll choose the number of blocks so that product of the number of threads per block and number of blocks exceeds the array size.  That way each thread will only need to do a single calculation."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "N = 2^10\ngrid_1d_d = cuzeros(N);\nnum_thr = 8\nnum_blk = ceil(Int,N//num_thr)\n@cuda threads=num_thr blocks=num_blk init_1d_grid!(grid_1d_d, N)\ngrid_1d_d"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Example Application:  Stellar limb darkening  (CPU version)\nSoon, we'll write a 2-d GPU kernel.  But first, we should make a kernel function for CPU calculations, so we'll hav something to compare to.  Below are function to compute the surface brightness of a limb-darkened stellar disk."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "\"Quadratic limb darkening law.  Takes μ = cos(angle between observer and center of star) and LD parameters, u1 and u2.\"\nlimb_darkening(μ, u1, u2) = zero(μ) <= μ <= one(μ) ? one(μ)-u1*(1-μ)-u2*(1-μ)^2 : zero(μ)\n\n\"Quadratic limb darkening law.  Takes x,y location on disk and LD parameters, u1 and u2.\"\nfunction limb_darkening(x, y, u1, u2)\n   r2 = x*x+y*y\n   r2 < one(r2) ? limb_darkening(sqrt(1-r2),u1,u2) : zero(r2)\nend"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can use these as the kernel to a `mapreduce` calculation on the CPU as shown below."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "\"Integrate over smooth stellar disk assumingn quadratic limb darkening law.  Uses N^2 evaluations over square.\"\nfunction calc_intensity_normalization(; u1=0.4, u2=0.26, N=256)\n    grid = range(-1,stop=1,length=N)\n    f(t::Tuple) = limb_darkening(t[1], t[2], u1, u2)\n    sum = mapreduce(f, +, ((x,y) for x in grid, y in grid)  )    \n    sum *= pi / length(grid)^2\nend"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "cin_cpu = calc_intensity_normalization(N=2^12)\n@benchmark cin_cpu = calc_intensity_normalization(N=2^12) samples=3"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Stellar limb darkening  (GPU version)\nRemember that there are several restrictions on GPU kernels.  Since the standard `sqrt` function includes error checking (looking for negative arguments), it's not allowed.  But CUDAnative provides a version of `sqrt` that can run on the GPU.  So we'll make a version of the limb darkeneing function for the GPU."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "function limb_darkening_gpu(x, y, u1, u2)\n    r2 = x*x+y*y\n   return r2 <= one(r2) ? limb_darkening(CUDAnative.sqrt(one(r2)-r2),u1,u2) : zero(r2)\nend"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "As it is that function takes and returns scalars.  For the GPU kernel, we need to direct the GPU how to assign work to each thread. \n    Below is one possible way to divide the work, potentially making use of a 2-D arrangement of threads within a block and 2-d grid of blocks."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "function apply_2d_grid!(out::AbstractArray{T,2},N::Integer,f,min=-1,max=1) where T<:Number\n    @assert size(out,1) == N\n    @assert size(out,2) == N\n    index_x = (blockIdx().x -1)*blockDim().x + threadIdx().x\n    stride_x = blockDim().x*gridDim().x\n    index_y = (blockIdx().y -1)*blockDim().y + threadIdx().y\n    stride_y = blockDim().y*gridDim().y\n    for i = index_x:stride_x:size(out,1)\n        for j = index_y:stride_y:size(out,2)\n            x = min+(max-min)*(i-1)/(N-1)\n            y = min+(max-min)*(j-1)/(N-1)\n            @inbounds out[i,j] = f(x,y) \n        end\n    end\n    return nothing\nend"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, we'll write a function to launch that GPU, specifying `N`, the number of samples along each axis (i.e., a total of $N^2$ evaluations), limb darkening parameters and optionally a CuAray that the result can be stored in."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "function calc_intensity_normalization_gpu(; u1=0.4, u2=0.26, N=256, gpu_workspace = cuzeros(N,N) )\n    thr = 8\n    blk = ceil(Int32,N//thr)\n    @cuda threads=(thr,thr) blocks=(blk,blk) apply_2d_grid!(gpu_workspace,N, \n            (x,y)->limb_darkening_gpu(x,y,u1,u2) )\n    reduce(+,gpu_workspace) * pi / N^2\nend"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's test our function."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "N= 2^12\ngrid_2d_d = cuzeros(N,N)\ncin_gpu = calc_intensity_normalization_gpu(N=N,gpu_workspace=grid_2d_d)"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Assuming that the test worked, proceed to benchmark the function."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "@benchmark calc_intensity_normalization_gpu(N=N,gpu_workspace=grid_2d_d) samples=3"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "How does performance of the GPU version compare to the CPU version?  What about if you run this on a CyberLAMP GPU node?\n\nINSERT RESPONCE\n\nIf you're feeling overwhelmed, then you can stop here.  On the other hand, if you think you might use this technique in your project, then you'll probably want to follow along below to see an example of performing a non-trivial calculation on the GPU efficiently.\n\n## An Absorption line\nNext we'll write several small functions that can be called by a GPU kernel, so that it can compute the spectrum of a star with both an absorption line and a star spot.  First, we'll create a Gaussian absorption line."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "\"Gaussian absorption line.  Named parameters for line loc[ation], width and depth.\"\ngaussian_line(x;loc=zero(x),width=one(x),depth=one(x)) = one(x) - depth*exp(-((x-loc)/width)^2/2)"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "\"Gaussian absorption line.  Named parameters for line loc[ation], width and depth.\"\ngaussian_line_gpu(x,loc=zero(x),width=one(x),depth=one(x)) = one(x) - depth*CUDAnative.exp(-((x-loc)/width)^2/2)"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "\"Calc thermal width of absorption line.  Named parameters for lambda, T[emperature], Z (atomic mass), and v_turb[ulent].\"\nfunction line_width_thermal(;lambda=1, Z=1, T=5778, v_turb=0 )\n   k_B = 1.3806485279e-23 # J/K\n   m_H = 1.6737236e-27 # kg\n   c = 299792458 # m/s\n   sqrt(2k_B/m_H *T/Z + v_turb^2 )*lambda/c\nend\nfrac_line_width_Fe = line_width_thermal(Z=55.845)"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "using Plots\n# pyplot() # Uncomment in you have trouble with default plotting backend"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's create a range of wavelengths and make a quick plot to make sure our `gaussian_line` function is working as we expect."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "lambda_min = 5549.8\nlambda_max = 5550.2\nlambda_mid = (lambda_min+lambda_max)/2\nnum_lambdas = 1024\nlambdas = range(lambda_min,stop=lambda_max,length=num_lambdas)"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "plot(lambdas,gaussian_line.(lambdas,loc=lambda_mid,width=lambda_mid*frac_line_width_Fe,depth=0.5))"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we'll create some functions that allow us to compute the velocity of each patch of the stellar surface towards the observed (assumed to be along the z axis)."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "\"Stellar rotation period as a function of sin(latitude).  For now assumes solid body rotation.\"\nfunction rotation_period(sinlat)\n    return 24.0  \nend"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "\"\"\"   patch_velocity_los(x,y; rstar, pole ) \nCompute line of sight velocity of a patch of stellar surface given by x,y (assumed in [-1,1]).\nOptional params: \n- rstar = 1: in R_sol (affects return velocity, but not x,y)\n- pole = (0,1,1): unit vector with stellar rotation axis\nDepends on:\n- rotation_period: Function that rotation period for give cos(latitude)\n\"\"\"\nfunction patch_velocity_los(x,y; rstar=one(x), pole=(zero(x), one(x), zero(x)) ) \n  polex, poley, polez = pole\n  v0 = 0.000168710673 # in (Rsol/day)/speed_of_light\n  z = sqrt(one(x)-x*x-y*y)  \n  sin_lat = x*polex+y*poley+z*polez\n  vmax = v0*rstar/rotation_period(sin_lat) \n  vmax*(polex*y-poley*x)\nend"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "\"\"\"   patch_velocity_los_gpu(x,y; rstar, pole ) \nCompute line of sight velocity of a patch of stellar surface given by x,y (assumed in [-1,1]).\nOptional params: \n- rstar = 1: in R_sol (affects return velocity, but not x,y)\n- pole = (0,1,1): unit vector with stellar rotation axis\nDepends on:\n- rotation_period: Function that rotation period for give cos(latitude)\n\"\"\"\nfunction patch_velocity_los_gpu(x,y; rstar=one(x), pole=(zero(x), one(x), zero(x)) ) \n  polex, poley, polez = pole\n  v0 = 0.000168710673 # in (Rsol/day)/speed_of_light\n  z = CUDAnative.sqrt(one(x)-x*x-y*y)  \n  sin_lat = x*polex+y*poley+z*polez\n  vmax = v0*rstar/rotation_period(sin_lat) \n  vmax*(polex*y-poley*x)\nend"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## A star spot\n\nNow, we'll define functions that can compute the surface intensity of each patch of the star's surface near a spot (before accounting for viewing angle and limb darkening)."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "\"\"\"   spot_intensity(x,y; spot_radius, spot_contrast, spot_loc )\nCompute intensity of patch of stellar surface given by x,y (assumed in [-1,1])\nReturns 1-spot_contrast if in spot and 1 if outside of spot (and in stellar disk)\nOptional params:\n- spot_radius: radius in sin(angle between spot center and patch) (default: 0)\n- spot_loc: unit vector for center of spot (default: (0,0,1) = center of disk )\n- spot_contranst: fractional reduction in intensity in spot\n\"\"\"\nfunction spot_intensity(x,y; spot_radius=zero(x), spot_contrast=one(x), spot_loc=(zero(x),zero(x),one(x)) )\n   r2 = x*x+y*y\n   if r2 > one(r2) \n        return zero(r2)\n   elseif spot_radius == zero(spot_radius)\n        return one(r2)\n   end\n   z = sqrt(one(r2)-r2)  \n   spot_x, spot_y, spot_z = spot_loc\n   cos_spot_patch = x*spot_x + y*spot_y + z*spot_z\n   dist_to_spot = one(r2)-cos_spot_patch^2 \n   intensity = dist_to_spot > spot_radius ? one(spot_contrast) : one(spot_contrast)-spot_contrast   \nend"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "\"\"\"   spot_intensity(x,y; spot_radius, spot_contrast, spot_loc )\nCompute intensity of patch of stellar surface given by x,y (assumed in [-1,1])\nReturns 1-spot_contrast if in spot and 1 if outside of spot (and in stellar disk)\nOptional params:\n- spot_radius: radius in sin(angle between spot center and patch) (default: 0)\n- spot_loc: unit vector for center of spot (default: (0,0,1) = center of disk )\n- spot_contranst: fractional reduction in intensity in spot\n\"\"\"\nfunction spot_intensity_gpu(x,y; spot_radius=zero(x), spot_contrast=one(x), spot_loc=(zero(x),zero(x),one(x)) )\n   r2 = x*x+y*y\n   if r2 > one(r2) \n        return zero(r2)\n   elseif spot_radius == zero(spot_radius)\n        return one(r2)\n   end\n   z = CUDAnative.sqrt(one(r2)-r2)  \n   spot_x, spot_y, spot_z = spot_loc\n   cos_spot_patch = x*spot_x + y*spot_y + z*spot_z\n   dist_to_spot = one(r2)-cos_spot_patch^2 \n   intensity = dist_to_spot > spot_radius ? one(spot_contrast) : one(spot_contrast)-spot_contrast   \nend"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, we'll write a function that runs on the CPU and returns the apparent brightness of each patch of the star's surface at a single wavelength.  We'll use this function to make a plot, to help us see what's going on."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "\"\"\" star_map(lambda)\nComputes map of stellar surface brightness for a Gaussian absorption line given limb darkening, rotation and a star spot.\nNamed parameters:\n- u1, u2: Quadratic limb darkening parameters\n- N: Number of points to evaluate in each axis (256)\n- line_loc, line_width, line_depth: properties of spectral line\n- spot_radius, spot_contrast, spot_loc: properties of star spot\n\"\"\"\nfunction star_map(lambda; u1=0.4, u2=0.26, N=256, \n        line_loc=0,line_width=0,line_depth=1,\n        spot_radius=0, spot_contrast=1, spot_loc=(0,0,1) )\n    xgrid = range(-1,stop=1,length=N)\n    function surface_brightness(t::Tuple)\n       x,y = t\n       r2 = x*x+y*y\n       if r2 > one(r2) \n          return zero(r2)\n       end\n       redshift = patch_velocity_los(x,y)\n       spec = gaussian_line(lambda*(1+redshift), loc=line_loc,width=line_width,depth=line_depth)\n       brightness = spot_intensity(x,y,\n            spot_radius=spot_radius,spot_contrast=spot_contrast,spot_loc=spot_loc)\n       ld = limb_darkening(sqrt(1-r2),u1,u2)\n       brightness * spec * ld\n    end\n    map(surface_brightness, ((x,y) for x in xgrid, y in xgrid)  ) .* pi / length(xgrid)^2 \nend"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "xgrid = range(-1,stop=1,length=256)\nygrid = range(-1,stop=1,length=256)\nsm = star_map(lambda_min, line_loc=lambda_mid,line_width=lambda_mid*frac_line_width_Fe,line_depth=0.5,\n        spot_radius=0.1,spot_loc=(-0.5,0.3,sqrt(1-0.5^2-0.3^2)) )\nplot(xgrid,xgrid,sm'./maximum(sm),st=:contourf)"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "For most stars, we can't spatially resolve the stellar disk, so we'd just observed the disk-integrated flux.  The next function is very similar to the previous, expect that use a `mapreduce` to compute the disk-integrated flux while reducing the memory overhead."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "\"\"\" disk_integrated_flux(lambda)\nComputes disk integrated stellar flux for a Gaussian absorption line given limb darkening, rotation and a star spot.\nNamed parameters:\n- u1, u2: Quadratic limb darkening parameters\n- N: Number of points to evaluate in each axis (256)\n- line_loc, line_width, line_depth: properties of spectral line\n- spot_radius, spot_contrast, spot_loc: properties of star spot\n\"\"\"\nfunction disk_integrated_flux(lambda; u1=0.4, u2=0.26, N=256, \n        line_loc=0,line_width=0,line_depth=1,\n        spot_radius=0, spot_contrast=1, spot_loc=(0,0,1) )\n    xgrid = range(-1,stop=1,length=N)\n    function surface_brightness(t::Tuple)\n       x,y = t\n       r2 = x*x+y*y\n       if r2 > one(r2) \n          return zero(r2)\n       end\n       redshift = patch_velocity_los(x,y)\n       spec = gaussian_line(lambda*(1+redshift), loc=line_loc,width=line_width,depth=line_depth)\n       brightness = spot_intensity(x,y,\n            spot_radius=spot_radius,spot_contrast=spot_contrast,spot_loc=spot_loc)\n       ld = limb_darkening(sqrt(1-r2),u1,u2)\n       brightness * spec * ld\n    end\n    sum = mapreduce(surface_brightness, +, ((x,y) for x in xgrid, y in xgrid)  )    \n    sum *= pi / length(xgrid)^2 \nend"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, let's use the function above to compute the disk-integrated spectrum and plot it to help us see what's going on.  We'll gradually turn on features to help visualize the effects of limb darkening, stellar rotation and the spot."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "@time spectrum_gaussian_line = gaussian_line.(lambdas,loc=lambda_mid,width=lambda_mid*frac_line_width_Fe,depth=0.5)\nnormalization = disk_integrated_flux(lambda_mid,line_loc=lambda_mid,line_width=lambda_mid*frac_line_width_Fe,line_depth=0.0)\n\n@time spectrum_add_rotation = disk_integrated_flux.(lambdas,line_loc=lambda_mid,line_width=lambda_mid*frac_line_width_Fe,line_depth=0.5) ./normalization\n@time spectrum_add_spot = disk_integrated_flux.(lambdas,line_loc=lambda_mid,line_width=lambda_mid*frac_line_width_Fe,line_depth=0.5,\n        spot_radius=0.1,spot_loc=(-0.5,0.3,sqrt(1-0.5^2-0.3^2))) ./normalization;"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "plot(lambdas,spectrum_gaussian_line, label=\"Gaussian line\")\nplot!(lambdas,spectrum_add_rotation, label=\"Add LD+Rotational\")\nplot!(lambdas,spectrum_add_spot, label=\"Add Spot\")"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "At first glance the blue green curve may look like a standard absorption line.  But if we subtract it's mirror image, we can see that the rotation is causing an asymetry in the line shape."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "plot(lambdas,(spectrum_add_spot.-view(spectrum_add_spot,length(spectrum_add_spot):-1:1)),label=\"Asmymetry\")"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Moving the calculation to the GPU\nWe need to make versions of the surface_brightness function that can run on the CPU."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "function surface_brightness_gpu(x,y,lambda,line_loc,line_width,line_depth,\n        spot_radius,spot_contrast,spot_loc,\n        u1,u2)\n       r2 = x*x+y*y\n       if r2 > one(r2) \n          return zero(r2)\n       end\n       redshift = patch_velocity_los_gpu(x,y)\n       spec = gaussian_line_gpu(lambda*(1+redshift), line_loc,line_width,line_depth)\n       brightness = spot_intensity_gpu(x,y,\n            spot_radius=spot_radius,spot_contrast=spot_contrast,spot_loc=spot_loc)\n       ld = limb_darkening(CUDAnative.sqrt(1-r2),u1,u2)\n       brightness * spec * ld\nend"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, we need a function to launch the GPU kernel, specifying the arrangement of threads within each block and the number of blocks.  We'll also perform the reduction on the GPU, so that it only needs to return the disk-integrated flux at one wavelength."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "function disk_integrated_flux_gpu(lambda; u1=0.4, u2=0.26, N::Integer=256, gpu_workspace = cuzeros(N,N),\n        line_loc=0,line_width=0,line_depth=1,\n        spot_radius=0, spot_contrast=1, spot_loc=(0,0,1)\n    )\n    thr = 8\n    blk = ceil(Int32,N//thr)\n    @cuda threads=(thr,thr) blocks=(blk,blk) apply_2d_grid!(gpu_workspace,N, \n            (x,y)->surface_brightness_gpu(x,y,lambda,line_loc,line_width,line_depth,\n                                            spot_radius,spot_contrast,spot_loc,  u1,u2) )\n    reduce(+,gpu_workspace) * pi / N^2\nend"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's test our GPU kernel and compare the results to the CPU version."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "spectrum_add_spot_gpu = disk_integrated_flux_gpu.(lambdas,line_loc=lambda_mid,line_width=lambda_mid*frac_line_width_Fe,line_depth=0.5,\n        spot_radius=0.1,spot_loc=(-0.5,0.3,sqrt(1-0.5^2-0.3^2))) /normalization;"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "minimum(abs.(spectrum_add_spot.-spectrum_add_spot_gpu))"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, benchmark the GPU and CPU versions and compare their performance."
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "@benchmark  disk_integrated_flux_gpu.(lambdas,line_loc=lambda_mid,line_width=lambda_mid*frac_line_width_Fe,line_depth=0.5,\n        spot_radius=0.1,spot_loc=(-0.5,0.3,sqrt(1-0.5^2-0.3^2))) /normalization samples=5"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        "@benchmark disk_integrated_flux.(lambdas,line_loc=lambda_mid,line_width=lambda_mid*frac_line_width_Fe,line_depth=0.5,\n        spot_radius=0.1,spot_loc=(-0.5,0.3,sqrt(1-0.5^2-0.3^2))) ./normalization samples=5"
      ],
      "metadata": {},
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "How does the performance of the GPU compare to the the CPU version on the ACI-I server?  What about on a CyberLAMP GPU node?\nIf one wanted to further improve the GPU performance, what changes would likely increase the performance further?  \n\nINSERT RESPONCE\n\nIf you're considering writing GPU kernels for your project code, then try experimenting with the number of threads per block to see how it affects the performance.  Report your findings.\n        \nINSERT RESPONCE"
      ],
      "metadata": {}
    },
    {
      "outputs": [],
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {},
      "execution_count": null
    }
  ],
  "nbformat_minor": 2,
  "metadata": {
    "language_info": {
      "file_extension": ".jl",
      "mimetype": "application/julia",
      "name": "julia",
      "version": "1.0.2"
    },
    "kernelspec": {
      "name": "julia-1.0",
      "display_name": "Julia 1.0.2",
      "language": "julia"
    }
  },
  "nbformat": 4
}
