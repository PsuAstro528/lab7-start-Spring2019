{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Astro 528, Lab 7, Exercise 1\n",
    "## GPU Computing I:  Getting Started & Linear Algebra\n",
    "\n",
    "In this lab exercise, we'll verify that we have access to a GPU, learn a little about its properties and benchmark some simple operations on a GPU to see how performance compares.  While most laptops have a GPU, most will either note be setup for general purpose computing or will be so low power that the benchmarking results won't be very informative.  Therefore, students are advised to run the exercises in this lab on ICS-ACI rather than their own system (unless they're confident they have setup their own system for GPU computing properly).  \n",
    "\n",
    "The ICS-ACI Jupyter notebook server and interactive desktop provided by the ICS-ACI portal are now using interactive notes that include a GPU, and students should be able to run all the code there.  However, the GPUs on the interactive nodes are relatively modest GPUs.  Therefore, after you've stepped through the notebook, you'll want to submit a PBS job, so you can run the calculations on one of the CyberLAMP GPU nodes.  For that step, you'll use the [command line interface](https://ics.psu.edu/computing-services/ics-aci-user-guide/#05-00-basics-aci-resources) to submit the PBS jobs, following a similar syntax as the [lab's 6 README](https://github.com/PsuAstro528/lab6-start/blob/master/README.md).  \n",
    "\n",
    "## Setting up Julia to use the GPU\n",
    "First, we need to make sure that your computer can find the [CUDA Toolkit](https://developer.nvidia.com/cuda-toolkit).  I've installed version 9.1.0 in `/gpfs/group/ebf11/default/astro528/cuda` and all students in the class should have read access to it.  In order for other packages to know where to find it, we'll set the environment variable `CUDA_HOME`.  You could do this in a dotfile (e.g., adding \n",
    "```bash \n",
    "export CUDA_HOME=/gpfs/group/ebf11/default/astro528/cuda\n",
    "```\n",
    "to your `~/.bashrc` *before* you start the Jupyter notebook server or interactive desktop file.  If that worked, then the next cell should return that path.  If it didn't work, then the `else` part of the next cell should set it for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The CUDA_HOME environment variable has been set to: /gpfs/group/ebf11/default/astro528/cuda\n"
     ]
    }
   ],
   "source": [
    "if haskey(ENV,\"CUDA_HOME\")\n",
    "    println(\"The CUDA_HOME environment variable has been set to: \",ENV[\"CUDA_HOME\"])\n",
    "else\n",
    "    println(\"The CUDA_HOME environment variable has not been set.  Setting it now...\")\n",
    "    ENV[\"CUDA_HOME\"] = \"/gpfs/group/ebf11/default/astro528/cuda\"\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, that we've told Julia were to find the CUDA toolkit, install the pacakages we'll be using, activate the current project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"/storage/work/a/axp1175/astro528/lab7-apellegrino/Project.toml\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using Pkg\n",
    "Pkg.activate(\".\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then install the necessary packages.  This instantiate should only need to be run once, assuming everything worked.  If you get errors, then you'll likely need to make sure CUDA_HOME is set correctly and then use `Pkg.build` to rebuild those libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m  Updating\u001b[22m\u001b[39m registry at `~/work/julia_depot/registries/General`\n",
      "\u001b[32m\u001b[1m  Updating\u001b[22m\u001b[39m git-repo `https://github.com/JuliaRegistries/General.git`\n",
      "\u001b[2K\u001b[?25h[1mFetching:\u001b[22m\u001b[39m [========================================>]  99.9 %0.0 %                                 ]  15.5 % %>                     ]  46.5 %\u001b[36m\u001b[1mFetching:\u001b[22m\u001b[39m [=====================>                   ]  50.2 %>             ]  65.6 % [=================================>       ]  81.2 % ]  96.1 %\u001b[32m\u001b[1m Installed\u001b[22m\u001b[39m CUDAapi ──── v0.6.0\n",
      "\u001b[32m\u001b[1m Installed\u001b[22m\u001b[39m GPUArrays ── v0.6.1\n",
      "\u001b[32m\u001b[1m Installed\u001b[22m\u001b[39m CUDAdrv ──── v1.0.1\n",
      "\u001b[32m\u001b[1m Installed\u001b[22m\u001b[39m CuArrays ─── v0.9.1\n",
      "\u001b[32m\u001b[1m Installed\u001b[22m\u001b[39m LLVM ─────── v1.0.0\n",
      "\u001b[32m\u001b[1m Installed\u001b[22m\u001b[39m CUDAnative ─ v1.0.1\n",
      "\u001b[32m\u001b[1m  Building\u001b[22m\u001b[39m CUDAdrv ───→ `~/work/julia_depot/packages/CUDAdrv/JWljj/deps/build.log`\n",
      "\u001b[32m\u001b[1m  Building\u001b[22m\u001b[39m LLVM ──────→ `~/work/julia_depot/packages/LLVM/tPWXv/deps/build.log`\n",
      "\u001b[32m\u001b[1m  Building\u001b[22m\u001b[39m CUDAnative → `~/work/julia_depot/packages/CUDAnative/Mdd3w/deps/build.log`\n",
      "\u001b[32m\u001b[1m  Building\u001b[22m\u001b[39m CuArrays ──→ `~/work/julia_depot/packages/CuArrays/PD3UJ/deps/build.log`\n"
     ]
    }
   ],
   "source": [
    "Pkg.instantiate()  # Only need to run once for the whole lab (assuming it works the first time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Don't worry if you get a warning about not finding the cudnn library.\n",
    "\n",
    "## CUDAdrv:  Julia interface to the CUDA driver\n",
    "\n",
    "For this first exercise, we'll install several packages individually to see what they do.  The [CUDAdrv.jl](https://juliagpu.gitlab.io/CUDAdrv.jl/) package is a Julia wrapper for the CUDA driver that allows programs to access an NVIDIA GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "using CUDAdrv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This provides very basic functionality, like querying what version of the CUDA Toolkit is being used,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "v\"9.1.0\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CUDAdrv.version()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "initializing the GPU, querying the name of the GPU being used,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Quadro K4000\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpu_dev = CuDevice(0)\n",
    "name(gpu_dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "querying how much RAM is avaliable on the GPU,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU has 2.94744873046875GB of RAM.\n"
     ]
    }
   ],
   "source": [
    "gpu_ram = Int64(totalmem(gpu_dev)) \n",
    "println(\"GPU has \",gpu_ram/1024^3, \"GB of RAM.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and the version indicating the current GPU's [\"compute capability\"](https://en.wikipedia.org/wiki/CUDA#GPUs_supported)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "v\"3.0.0\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "capability(gpu_dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In principle, the compute capability tells you the technical sepcifications of your GPU that would be needed to do fairly low-level programming.  Rather than [looking up the specs of your graphics card online](https://en.wikipedia.org/wiki/List_of_Nvidia_graphics_processing_units), you can query [a large list of GPU attributes](https://github.com/JuliaGPU/CUDAdrv.jl/blob/master/src/devices.jl#L60).  For example, how many multi-processors does the current GPU have?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attribute(gpu_dev,CUDAdrv.MULTIPROCESSOR_COUNT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GPUs execute many calculations at once, typically thousands or even hundreds of thousands threads are run in a single call to the GPU kernel.  The threads are grouped into \"blocks\" and the GPU can distribute different blocks to different multiprocessors as it sees fit.  Each blocks may be broken down into one or multiple \"warps\" which are run on the same multiprocessor, but not necessarily at the same time.  All computations in one warp are executed in parallel on a single multiprocessor.  Let's check the maximum number of threads per block and how many threads are in one warp on your GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1024"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attribute(gpu_dev,CUDAdrv.MAX_THREADS_PER_BLOCK)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "warpsize(gpu_dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have fewer threads in a block, than the warp size, then then some of the arithmetic units in the multiprocessor won't be used effectively.  \n",
    "Nevertheless, sometimes this is necessary, because there's a fixed number of registers per block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65536"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attribute(gpu_dev,CUDAdrv.MAX_REGISTERS_PER_BLOCK)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If one wants to get the full power of GPUs, then one is likely to do at least some low-level GPU programming in which one would need to make use of this information to choose how to divide up the work among threads and blocks efficiently.  \n",
    "\n",
    "### GPUArrays:  A High-level Julia interface to GPU programming\n",
    "\n",
    "For this exercise, we'll use the [GPUArrays.jl](https://github.com/JuliaGPU/GPUArrays.jl) package that provides a high-level interface that hides the above details from the programmer.  Different GPU manufacturers provide different functionality and libraries.  The GPUs at ICS-ACI are NVIDIA GPUs, and these are most efficiently programmed using [CUDA](https://en.wikipedia.org/wiki/CUDA).  On the other hand, AMD GPUs are most efficiently programmed using [OpenCL](https://en.wikipedia.org/wiki/OpenCL).  Some programmers perfer to use OpenCL, since CUDA is a proprietary language.  Julia has mid/high-level libraries for array operations for using either CUDA (i.e., [CuArrays.jl](https://github.com/JuliaGPU/CuArrays.jl)) or OpenCL (i.e., [CLArrays.jl](https://github.com/JuliaGPU/CLArrays.jl)).  It would be nice to be able to write code that can run with either type of GPU.  Indeed, the [GPUArrays.jl](https://github.com/JuliaGPU/GPUArrays.jl) package provides just that.  For many applications, [GPUArrays.jl](https://github.com/JuliaGPU/GPUArrays.jl) provides all you need to get orders of magnitude speed-up relative to a CPU.  \n",
    "\n",
    "Since this is our first time using these packages, let's load them one at a time, just in case there are any error messages.  Since CuArrays is the lower-level package, let's first make sure that load successfully."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Precompiling CuArrays [3a865a2d-5b23-5a0f-bc46-62713ec82fae]\n",
      "└ @ Base loading.jl:1192\n"
     ]
    }
   ],
   "source": [
    "using CuArrays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assuming that CuArrays loaded successfuly, proceed to load the GPUArrays package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "using GPUArrays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we'll benchmark some linear algebra.  Because linear algebra is so common, there are efficient [BLAS libraries](https://en.wikipedia.org/wiki/Basic_Linear_Algebra_Subprograms) avaliable for both CPUs and GPU.\n",
    "Create some matrices and arrays for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "N = 1024\n",
    "A_h = randn(N,N)\n",
    "x_h = randn(N);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "b_h = A_h*x_h;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To perform calculations on a GPU, we'll need to send the data from the CPU to the GPU.  The CuArrays pacakge provides a datatype `CuDeviceArray` for arrays that live on the device.  Manually specifying when to send data back and forth can be good for efficiency, but does require more care.  So instead, we use `CuArray`'s that take care of moving the data between the CPU (or \"host\") memory system and the GPU (or \"device\") memory system for us.  \n",
    "\n",
    "We can create a 'CuArray' from an existing Array simply with the `cu(.)` function.  Then we can proceed to do arithmetic on them with the same syntax as when using standard Arrays.  (Generic programming is amazing!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1024-element CuArray{Float32,1}:\n",
       "  -4.176999 \n",
       "  13.872379 \n",
       "  -5.3182335\n",
       "  53.307156 \n",
       "  12.307359 \n",
       " -29.872375 \n",
       "  65.09448  \n",
       "  39.36636  \n",
       " -26.397562 \n",
       "  -4.6430345\n",
       "  67.214676 \n",
       " -23.481934 \n",
       " -10.636773 \n",
       "   ⋮        \n",
       " -38.31561  \n",
       " -17.82618  \n",
       "   4.512912 \n",
       " -67.2815   \n",
       " -38.11163  \n",
       "  28.772501 \n",
       " -16.011162 \n",
       "  29.441952 \n",
       "  14.275597 \n",
       " -17.908827 \n",
       "  14.635857 \n",
       "  37.349983 "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A_d = cu(A_h)\n",
    "x_d = cu(x_h)\n",
    "b_d = A_d*x_d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, note the type of each variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(CuArray{Float32,2}, CuArray{Float32,1}, CuArray{Float32,1})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "typeof(A_d), typeof(x_d), typeof(b_d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By using a CuArray, the result calculation is also stored as a CuArray and left on the GPU.  While CuArrays let us access individual elements, if we want to look at the whole array, then it would be faster to copy all the data at once to CPU.  We can bring the full result back to the host, using `Array(.)` or `collect(.)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1024-element Array{Float32,1}:\n",
       "  -4.176999 \n",
       "  13.872379 \n",
       "  -5.3182335\n",
       "  53.307156 \n",
       "  12.307359 \n",
       " -29.872375 \n",
       "  65.09448  \n",
       "  39.36636  \n",
       " -26.397562 \n",
       "  -4.6430345\n",
       "  67.214676 \n",
       " -23.481934 \n",
       " -10.636773 \n",
       "   ⋮        \n",
       " -38.31561  \n",
       " -17.82618  \n",
       "   4.512912 \n",
       " -67.2815   \n",
       " -38.11163  \n",
       "  28.772501 \n",
       " -16.011162 \n",
       "  29.441952 \n",
       "  14.275597 \n",
       " -17.908827 \n",
       "  14.635857 \n",
       "  37.349983 "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b_comp_h = Array(b_d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll compare the results.  What do you expect for the maximum difference in any element in `b`?\n",
    "        \n",
    "**The mantissa of the single-precision IEEE 754 standard is 23 bits long which is about 7 digits of information, so about 10^-7 * max(b)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.4707735255091734e-5"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maximum(b_comp_h .- b_h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How did the results compare to your expectations?  \n",
    "\n",
    "**max(b) is of order 10^2 so this is about right, maybe a bit larger.**\n",
    "\n",
    "One thing to keep in mind is that most \"consumer grade\" GPUs are designed to only perform single-precision arithmetic.  Even GPUs that do support double precission are often significantly slower at double precission arithmetic than single precission.  The difference is particularly noticable for \"consumer grade\" GPUs.  When we need double precission, we can specify that explicitly.  Below we will use double precision on the GPU and test its accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.9895196601282805e-13"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A_d64 = CuArray{Float64}(A_h)\n",
    "x_d64 = CuArray{Float64}(x_h)\n",
    "b_d64 = A_d64*x_d64\n",
    "maximum(Array(b_d64) .- b_h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, how do the results compare to your expectations?\n",
    "\n",
    "**This is about the precision of double precision floats, but also I wonder why there is any difference at all if the calculations are the same with the same level of precision.**\n",
    "\n",
    "\n",
    "## Benchmarking GPU for Linear Algebra\n",
    "Now, we'll do some benchmarking of the CPU vs GPU, so let's load the usual BenchmarkTools package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Recompiling stale cache file /storage/home/axp1175/work/julia_depot/compiled/v1.0/BenchmarkTools/ZXPQo.ji for BenchmarkTools [6e4b80f9-dd63-53aa-95a3-0cdb28fa8baf]\n",
      "└ @ Base loading.jl:1190\n"
     ]
    }
   ],
   "source": [
    "using BenchmarkTools, Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we'll be able to use the exact same macros to benchmark code running on either the CPU or the GPU.  To keep things reasonably fast, we'll specify that we only want Julia to benchmark each calculation a few times.  \n",
    "Calls to the GPU run asynchronously.  So if we want to benchmark how long is required to the calculation to complete, we need to tell Julia to wait until the calculation has been synchronized.  We can do that either with the `@sync` macro in CuArrays or with the `synchronize(.)` function in GPUArrays to make our code more general.  `@sync` makes everyone wait until everything is complete.  `synchronize(x)` only waits until the array `x` is synchronized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  memory estimate:  592 bytes\n",
       "  allocs estimate:  22\n",
       "  --------------\n",
       "  minimum time:     10.724 μs (0.00% GC)\n",
       "  median time:      14.457 μs (0.00% GC)\n",
       "  mean time:        25.627 μs (0.00% GC)\n",
       "  maximum time:     75.353 μs (0.00% GC)\n",
       "  --------------\n",
       "  samples:          5\n",
       "  evals/sample:     1"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@benchmark b_d = $A_d*$x_d samples=5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How long does it take to launch the GPU kernel and exit?\n",
    "\n",
    "**~15 μs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  memory estimate:  704 bytes\n",
       "  allocs estimate:  26\n",
       "  --------------\n",
       "  minimum time:     103.621 μs (0.00% GC)\n",
       "  median time:      117.066 μs (0.00% GC)\n",
       "  mean time:        188.971 μs (0.00% GC)\n",
       "  maximum time:     351.725 μs (0.00% GC)\n",
       "  --------------\n",
       "  samples:          5\n",
       "  evals/sample:     1"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@benchmark CuArrays.@sync( b_d = $A_d*$x_d) samples=5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How long did it take to complete the calculation and store to to an array on the GPU?  How does this compare to the cost of launching the kernel?  What are the implications for the ammount of work you'd want per GPU call in order to make efficient use of the GPU?\n",
    "\n",
    "**~115 μs, several times the cost of lauching the kernel itself. Therefore the work per GPU call would have to be much larger to make it efficient.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Building the CUDAnative run-time library for your sm_30 device, this might take a while...\n",
      "└ @ CUDAnative /storage/home/axp1175/work/julia_depot/packages/CUDAnative/Mdd3w/src/compiler/rtlib.jl:156\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  memory estimate:  2.16 KiB\n",
       "  allocs estimate:  62\n",
       "  --------------\n",
       "  minimum time:     77.809 μs (0.00% GC)\n",
       "  median time:      82.262 μs (0.00% GC)\n",
       "  mean time:        92.888 μs (0.00% GC)\n",
       "  maximum time:     142.107 μs (0.00% GC)\n",
       "  --------------\n",
       "  samples:          5\n",
       "  evals/sample:     1"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@benchmark ( b_d .= $A_d*$x_d;  GPUArrays.synchronize(b_d); ) samples=5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can compare that to double precission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  memory estimate:  2.16 KiB\n",
       "  allocs estimate:  62\n",
       "  --------------\n",
       "  minimum time:     126.050 μs (0.00% GC)\n",
       "  median time:      126.492 μs (0.00% GC)\n",
       "  mean time:        147.182 μs (0.00% GC)\n",
       "  maximum time:     227.539 μs (0.00% GC)\n",
       "  --------------\n",
       "  samples:          5\n",
       "  evals/sample:     1"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@benchmark ( b_d64 .= $A_d64*$x_d64;  GPUArrays.synchronize(b_d64); ) samples=5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we'll want to perform benchmarks for several problem sizes, I've provided a function `run_benchmarks` to make things a little easier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "run_benchmarks"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" run_benchmarks(N; opts)\n",
    "Benchmark matrix-vector multiplication and optionally linear solve.\n",
    "Optional arguments:\n",
    "- num_samples:  How many times to perform each calculation being benchmarked\n",
    "- calc_solve: Whether to benchmark linear solve (false)\n",
    "- run_cpu:  Whether to perform benchmarks on cpu (true)\n",
    "- run_gpu:  Whether to perform benchmarks on gpu (false)\n",
    "- verbose:  Whether to print status updates.\n",
    "Output: A dictionary with results of each benchmark performed and \n",
    "        optionally the difference in final CPU and GPU calculations (if both are run).  \n",
    "\"\"\"\n",
    "function run_benchmarks(N::Integer; num_samples=3, run_cpu=true, run_gpu=false,\n",
    "                            gpu_type = Float32, mat_vec=true, mat_mat=false, compare=false, verbose=false )\n",
    "   verbose && println(\"Benchmarking with problem size = \",N)\n",
    "   A_h = randn(N,N)\n",
    "   x_h = randn(N)\n",
    "   output = Dict()\n",
    "   if run_gpu\n",
    "      A_d = CuArray{gpu_type}(A_h)\n",
    "      x_d = CuArray{gpu_type}(x_h)\n",
    "   end\n",
    "   if mat_vec\n",
    "      if run_cpu\n",
    "         verbose && println(\"Benchmarking matrix-vector multiply on CPU\")\n",
    "         # The `$` signs below specify that we want benchmark to use the local variables, rather than global variables with same name\n",
    "         output[\"cpu_mat_vec_mul\"] = @benchmark b_h = $A_h*$x_h samples=num_samples\n",
    "      end\n",
    "      if run_gpu\n",
    "         verbose && println(\"Benchmarking matrix-vector multiply on GPU\")\n",
    "         #output[\"gpu_mat_vec_mul\"] = @benchmark CuArrays.@sync( b_d = $A_d*$x_d) samples=num_samples\n",
    "         output[\"gpu_mat_vec_mul\"] = @benchmark ( b_d = $A_d*$x_d; GPUArrays.synchronize(b_d) ) samples=num_samples\n",
    "      end\n",
    "      if run_cpu && run_gpu && compare\n",
    "        b_h = A_h*x_h\n",
    "        b_d = A_d*x_d\n",
    "        output[\"diff_mat_vec_mul\"] = convert(typeof(b_h),Array(b_d)).-b_h\n",
    "      end\n",
    "   end\n",
    "   if mat_mat\n",
    "      if run_cpu\n",
    "         verbose && println(\"Benchmarking matrix-matrix multiply on CPU\")\n",
    "         # The `$` signs below specify that we want benchmark to use the local variables, rather than global variables with same name\n",
    "         output[\"cpu_mat_mat_mul\"] = @benchmark Asq_h = $A_h*$A_h' samples=num_samples\n",
    "      end\n",
    "      if run_gpu\n",
    "         verbose && println(\"Benchmarking matrix-matrix multiply on GPU\")\n",
    "         output[\"gpu_mat_mat_mul\"] = @benchmark ( Asq_d = $A_d*$A_d'; GPUArrays.synchronize(Asq_d) ) samples=num_samples\n",
    "      end\n",
    "      if run_cpu && run_gpu && compare\n",
    "        Asq_h = A_h*A_h'\n",
    "        Asq_d = A_d*A_d'\n",
    "        output[\"diff_mat_mat_mul\"] = convert(typeof(Asq_h),Array(Asq_d)).-Asq_h\n",
    "      end\n",
    "   end\n",
    "   return output\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, do a quick test to see how it works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Benchmarking with problem size = 128\n",
      "Benchmarking matrix-vector multiply on CPU\n",
      "Benchmarking matrix-vector multiply on GPU\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dict{Any,Any} with 3 entries:\n",
       "  \"diff_mat_vec_mul\" => [4.7066e-7, 7.60654e-7, 2.18365e-7, -1.05561e-7, 5.6252…\n",
       "  \"gpu_mat_vec_mul\"  => Trial(28.267 μs)\n",
       "  \"cpu_mat_vec_mul\"  => Trial(3.623 μs)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "have_gpu = @isdefined GPUArrays\n",
    "benchmark_result = run_benchmarks(128,verbose=true,mat_vec=true,run_gpu=have_gpu,compare=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll extract the median run time for the multiplication using the CPU with expressions like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3708.875"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "median(benchmark_result[\"cpu_mat_vec_mul\"].times)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And compare this to the performance using double precission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Benchmarking with problem size = 128\n",
      "Benchmarking matrix-vector multiply on CPU\n",
      "Benchmarking matrix-vector multiply on GPU\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3674.75"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "have_gpu = @isdefined GPUArrays\n",
    "benchmark_result = run_benchmarks(128,verbose=true,gpu_type=Float64,mat_vec=true,run_gpu=have_gpu,compare=true)\n",
    "median(benchmark_result[\"cpu_mat_vec_mul\"].times)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's perform run some benchmarks and plot the results.  After you've made your first plot, you may want to increase the range of problem sizes slightly to extend your plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Recompiling stale cache file /storage/home/axp1175/work/julia_depot/compiled/v1.0/Plots/ld3vC.ji for Plots [91a5bcdd-55d7-5caf-9e0b-520d859cae80]\n",
      "└ @ Base loading.jl:1190\n"
     ]
    }
   ],
   "source": [
    "using Plots\n",
    "#pyplot()  # in case gr() gives you trouble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11-element Array{Dict{Any,Any},1}:\n",
       " Dict(\"cpu_mat_mat_mul\"=>Trial(359.779 ns),\"gpu_mat_mat_mul\"=>Trial(27.821 μs),\"gpu_mat_vec_mul\"=>Trial(24.904 μs),\"cpu_mat_vec_mul\"=>Trial(93.244 ns)) \n",
       " Dict(\"cpu_mat_mat_mul\"=>Trial(803.026 ns),\"gpu_mat_mat_mul\"=>Trial(27.670 μs),\"gpu_mat_vec_mul\"=>Trial(26.736 μs),\"cpu_mat_vec_mul\"=>Trial(103.627 ns))\n",
       " Dict(\"cpu_mat_mat_mul\"=>Trial(2.380 μs),\"gpu_mat_mat_mul\"=>Trial(26.958 μs),\"gpu_mat_vec_mul\"=>Trial(26.322 μs),\"cpu_mat_vec_mul\"=>Trial(206.172 ns))  \n",
       " Dict(\"cpu_mat_mat_mul\"=>Trial(7.183 μs),\"gpu_mat_mat_mul\"=>Trial(28.257 μs),\"gpu_mat_vec_mul\"=>Trial(29.276 μs),\"cpu_mat_vec_mul\"=>Trial(309.011 ns))  \n",
       " Dict(\"cpu_mat_mat_mul\"=>Trial(30.021 μs),\"gpu_mat_mat_mul\"=>Trial(34.604 μs),\"gpu_mat_vec_mul\"=>Trial(26.685 μs),\"cpu_mat_vec_mul\"=>Trial(1.273 μs))   \n",
       " Dict(\"cpu_mat_mat_mul\"=>Trial(155.759 μs),\"gpu_mat_mat_mul\"=>Trial(66.124 μs),\"gpu_mat_vec_mul\"=>Trial(28.283 μs),\"cpu_mat_vec_mul\"=>Trial(3.478 μs))  \n",
       " Dict(\"cpu_mat_mat_mul\"=>Trial(974.506 μs),\"gpu_mat_mat_mul\"=>Trial(104.688 μs),\"gpu_mat_vec_mul\"=>Trial(46.002 μs),\"cpu_mat_vec_mul\"=>Trial(16.906 μs))\n",
       " Dict(\"cpu_mat_mat_mul\"=>Trial(6.736 ms),\"gpu_mat_mat_mul\"=>Trial(500.982 μs),\"gpu_mat_vec_mul\"=>Trial(46.988 μs),\"cpu_mat_vec_mul\"=>Trial(64.473 μs))  \n",
       " Dict(\"cpu_mat_mat_mul\"=>Trial(53.010 ms),\"gpu_mat_mat_mul\"=>Trial(3.533 ms),\"gpu_mat_vec_mul\"=>Trial(75.110 μs),\"cpu_mat_vec_mul\"=>Trial(297.332 μs))  \n",
       " Dict(\"cpu_mat_mat_mul\"=>Trial(419.112 ms),\"gpu_mat_mat_mul\"=>Trial(27.229 ms),\"gpu_mat_vec_mul\"=>Trial(210.364 μs),\"cpu_mat_vec_mul\"=>Trial(3.410 ms)) \n",
       " Dict(\"cpu_mat_mat_mul\"=>Trial(3.210 s),\"gpu_mat_mat_mul\"=>Trial(214.510 ms),\"gpu_mat_vec_mul\"=>Trial(793.243 μs),\"cpu_mat_vec_mul\"=>Trial(14.261 ms))  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "problem_sizes = [2^i for i in 2:12]\n",
    "benchmark_results32 = map( s->run_benchmarks(s,mat_mat=true,run_gpu=have_gpu,gpu_type=Float32), problem_sizes )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"utf-8\"?>\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"600\" height=\"400\" viewBox=\"0 0 2400 1600\">\n",
       "<defs>\n",
       "  <clipPath id=\"clip3400\">\n",
       "    <rect x=\"0\" y=\"0\" width=\"2000\" height=\"2000\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<defs>\n",
       "  <clipPath id=\"clip3401\">\n",
       "    <rect x=\"0\" y=\"0\" width=\"2400\" height=\"1600\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<polygon clip-path=\"url(#clip3401)\" points=\"\n",
       "0,1600 2400,1600 2400,0 0,0 \n",
       "  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<defs>\n",
       "  <clipPath id=\"clip3402\">\n",
       "    <rect x=\"480\" y=\"0\" width=\"1681\" height=\"1600\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<polygon clip-path=\"url(#clip3401)\" points=\"\n",
       "212.353,1440.48 2321.26,1440.48 2321.26,125.984 212.353,125.984 \n",
       "  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<defs>\n",
       "  <clipPath id=\"clip3403\">\n",
       "    <rect x=\"212\" y=\"125\" width=\"2110\" height=\"1315\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<polyline clip-path=\"url(#clip3403)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  371.516,1440.48 371.516,125.984 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip3403)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  868.899,1440.48 868.899,125.984 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip3403)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  1366.28,1440.48 1366.28,125.984 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip3403)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  1863.67,1440.48 1863.67,125.984 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip3403)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  212.353,1234.21 2321.26,1234.21 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip3403)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  212.353,905.236 2321.26,905.236 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip3403)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  212.353,576.263 2321.26,576.263 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip3403)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  212.353,247.29 2321.26,247.29 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip3401)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  212.353,1440.48 2321.26,1440.48 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip3401)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  212.353,1440.48 212.353,125.984 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip3401)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  371.516,1440.48 371.516,1420.77 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip3401)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  868.899,1440.48 868.899,1420.77 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip3401)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1366.28,1440.48 1366.28,1420.77 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip3401)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1863.67,1440.48 1863.67,1420.77 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip3401)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  212.353,1234.21 243.986,1234.21 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip3401)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  212.353,905.236 243.986,905.236 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip3401)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  212.353,576.263 243.986,576.263 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip3401)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  212.353,247.29 243.986,247.29 \n",
       "  \"/>\n",
       "<g clip-path=\"url(#clip3401)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:middle;\" transform=\"rotate(0, 371.516, 1494.48)\" x=\"371.516\" y=\"1494.48\">2.5</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip3401)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:middle;\" transform=\"rotate(0, 868.899, 1494.48)\" x=\"868.899\" y=\"1494.48\">5.0</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip3401)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:middle;\" transform=\"rotate(0, 1366.28, 1494.48)\" x=\"1366.28\" y=\"1494.48\">7.5</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip3401)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:middle;\" transform=\"rotate(0, 1863.67, 1494.48)\" x=\"1863.67\" y=\"1494.48\">10.0</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip3401)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:end;\" transform=\"rotate(0, 188.353, 1251.71)\" x=\"188.353\" y=\"1251.71\">-6</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip3401)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:end;\" transform=\"rotate(0, 188.353, 922.736)\" x=\"188.353\" y=\"922.736\">-4</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip3401)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:end;\" transform=\"rotate(0, 188.353, 593.763)\" x=\"188.353\" y=\"593.763\">-2</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip3401)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:end;\" transform=\"rotate(0, 188.353, 264.79)\" x=\"188.353\" y=\"264.79\">0</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip3401)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:84px; text-anchor:middle;\" transform=\"rotate(0, 1266.81, 73.2)\" x=\"1266.81\" y=\"73.2\">Float32</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip3401)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:66px; text-anchor:middle;\" transform=\"rotate(0, 1266.81, 1590.4)\" x=\"1266.81\" y=\"1590.4\">log_2 N</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip3401)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:66px; text-anchor:middle;\" transform=\"rotate(-90, 57.6, 783.233)\" x=\"57.6\" y=\"783.233\">log_10 (Time/s)</text>\n",
       "</g>\n",
       "<polyline clip-path=\"url(#clip3403)\" style=\"stroke:#009af9; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  272.039,1403.28 470.992,1391.81 669.946,1335.16 868.899,1315.01 1067.85,1214.97 1266.81,1144.61 1465.76,1028.36 1664.71,872.429 1863.67,817.482 2062.62,651.608 \n",
       "  2261.57,550.752 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip3403)\" style=\"stroke:#e26f46; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  272.039,997.194 470.992,996.675 669.946,996.031 868.899,991.826 1067.85,992.46 1266.81,988.411 1465.76,946.428 1664.71,958.433 1863.67,924.484 2062.62,848.905 \n",
       "  2261.57,755.981 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip3403)\" style=\"stroke:#3da44d; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  272.039,1301.97 470.992,1249.03 669.946,1164.84 868.899,1092.98 1067.85,990.268 1266.81,873.406 1465.76,729.461 1664.71,604.369 1863.67,456.929 2062.62,309.02 \n",
       "  2261.57,163.187 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip3403)\" style=\"stroke:#c271d2; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  272.039,990.967 470.992,993.445 669.946,994.297 868.899,990.033 1067.85,974.652 1266.81,933.222 1465.76,901.676 1664.71,790.033 1863.67,650.517 2062.62,504.612 \n",
       "  2261.57,357.257 \n",
       "  \"/>\n",
       "<polygon clip-path=\"url(#clip3401)\" points=\"\n",
       "284.353,511.904 933.585,511.904 933.585,209.504 284.353,209.504 \n",
       "  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<polyline clip-path=\"url(#clip3401)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  284.353,511.904 933.585,511.904 933.585,209.504 284.353,209.504 284.353,511.904 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip3401)\" style=\"stroke:#009af9; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  308.353,269.984 452.353,269.984 \n",
       "  \"/>\n",
       "<g clip-path=\"url(#clip3401)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:start;\" transform=\"rotate(0, 476.353, 287.484)\" x=\"476.353\" y=\"287.484\">CPU mat_vec_mul</text>\n",
       "</g>\n",
       "<polyline clip-path=\"url(#clip3401)\" style=\"stroke:#e26f46; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  308.353,330.464 452.353,330.464 \n",
       "  \"/>\n",
       "<g clip-path=\"url(#clip3401)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:start;\" transform=\"rotate(0, 476.353, 347.964)\" x=\"476.353\" y=\"347.964\">GPU mat_vec_mul</text>\n",
       "</g>\n",
       "<polyline clip-path=\"url(#clip3401)\" style=\"stroke:#3da44d; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  308.353,390.944 452.353,390.944 \n",
       "  \"/>\n",
       "<g clip-path=\"url(#clip3401)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:start;\" transform=\"rotate(0, 476.353, 408.444)\" x=\"476.353\" y=\"408.444\">CPU mat_mat_mul</text>\n",
       "</g>\n",
       "<polyline clip-path=\"url(#clip3401)\" style=\"stroke:#c271d2; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  308.353,451.424 452.353,451.424 \n",
       "  \"/>\n",
       "<g clip-path=\"url(#clip3401)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:start;\" transform=\"rotate(0, 476.353, 468.924)\" x=\"476.353\" y=\"468.924\">GPU mat_mat_mul</text>\n",
       "</g>\n",
       "</svg>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cpu_times = map(i->median(benchmark_results32[i][\"cpu_mat_vec_mul\"].times),1:length(problem_sizes))\n",
    "plt = plot(log2.(problem_sizes),log10.(cpu_times*1e-9), label=\"CPU mat_vec_mul\",xaxis=\"log_2 N\", yaxis=\"log_10 (Time/s)\", title=\"Float32\", legend=:topleft)\n",
    "if haskey(benchmark_results32[1],\"gpu_mat_vec_mul\")\n",
    "    gpu_times = map(i->median(benchmark_results32[i][\"gpu_mat_vec_mul\"].times),1:length(problem_sizes))\n",
    "    plt = plot!(log2.(problem_sizes),log10.(gpu_times*1e-9), label=\"GPU mat_vec_mul\")\n",
    "end\n",
    "if haskey(benchmark_results32[1],\"cpu_mat_mat_mul\")\n",
    "    cpu_times = map(i->median(benchmark_results32[i][\"cpu_mat_mat_mul\"].times),1:length(problem_sizes))\n",
    "    plt = plot!(log2.(problem_sizes),log10.(cpu_times*1e-9), label=\"CPU mat_mat_mul\")\n",
    "end\n",
    "if haskey(benchmark_results32[1],\"gpu_mat_mat_mul\")\n",
    "    gpu_times = map(i->median(benchmark_results32[i][\"gpu_mat_mat_mul\"].times),1:length(problem_sizes))\n",
    "    plt = plot!(log2.(problem_sizes),log10.(gpu_times*1e-9), label=\"GPU mat_mat_mul\")\n",
    "end\n",
    "display(plt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8-element Array{Dict{Any,Any},1}:\n",
       " Dict(\"gpu_mat_vec_mul\"=>Trial(25.441 μs),\"cpu_mat_vec_mul\"=>Trial(119.645 ns))\n",
       " Dict(\"gpu_mat_vec_mul\"=>Trial(26.006 μs),\"cpu_mat_vec_mul\"=>Trial(109.604 ns))\n",
       " Dict(\"gpu_mat_vec_mul\"=>Trial(26.904 μs),\"cpu_mat_vec_mul\"=>Trial(149.027 ns))\n",
       " Dict(\"gpu_mat_vec_mul\"=>Trial(27.316 μs),\"cpu_mat_vec_mul\"=>Trial(301.410 ns))\n",
       " Dict(\"gpu_mat_vec_mul\"=>Trial(33.408 μs),\"cpu_mat_vec_mul\"=>Trial(983.414 ns))\n",
       " Dict(\"gpu_mat_vec_mul\"=>Trial(29.057 μs),\"cpu_mat_vec_mul\"=>Trial(3.630 μs))  \n",
       " Dict(\"gpu_mat_vec_mul\"=>Trial(51.784 μs),\"cpu_mat_vec_mul\"=>Trial(17.811 μs)) \n",
       " Dict(\"gpu_mat_vec_mul\"=>Trial(54.377 μs),\"cpu_mat_vec_mul\"=>Trial(68.183 μs)) "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "problem_sizes = [2^i for i in 2:9]\n",
    "benchmark_results64 = map( s->run_benchmarks(s,mat_mat=false,run_gpu=have_gpu,gpu_type=Float64), problem_sizes )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"utf-8\"?>\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"600\" height=\"400\" viewBox=\"0 0 2400 1600\">\n",
       "<defs>\n",
       "  <clipPath id=\"clip3600\">\n",
       "    <rect x=\"0\" y=\"0\" width=\"2000\" height=\"2000\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<defs>\n",
       "  <clipPath id=\"clip3601\">\n",
       "    <rect x=\"0\" y=\"0\" width=\"2400\" height=\"1600\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<polygon clip-path=\"url(#clip3601)\" points=\"\n",
       "0,1600 2400,1600 2400,0 0,0 \n",
       "  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<defs>\n",
       "  <clipPath id=\"clip3602\">\n",
       "    <rect x=\"480\" y=\"0\" width=\"1681\" height=\"1600\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<polygon clip-path=\"url(#clip3601)\" points=\"\n",
       "212.353,1440.48 2321.26,1440.48 2321.26,125.984 212.353,125.984 \n",
       "  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<defs>\n",
       "  <clipPath id=\"clip3603\">\n",
       "    <rect x=\"212\" y=\"125\" width=\"2110\" height=\"1315\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<polyline clip-path=\"url(#clip3603)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  272.039,1440.48 272.039,125.984 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip3603)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  840.477,1440.48 840.477,125.984 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip3603)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  1408.92,1440.48 1408.92,125.984 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip3603)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  1977.35,1440.48 1977.35,125.984 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip3603)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  212.353,1420.33 2321.26,1420.33 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip3603)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  212.353,1008.6 2321.26,1008.6 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip3603)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  212.353,596.879 2321.26,596.879 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip3603)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  212.353,185.156 2321.26,185.156 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip3601)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  212.353,1440.48 2321.26,1440.48 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip3601)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  212.353,1440.48 212.353,125.984 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip3601)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  272.039,1440.48 272.039,1420.77 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip3601)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  840.477,1440.48 840.477,1420.77 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip3601)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1408.92,1440.48 1408.92,1420.77 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip3601)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1977.35,1440.48 1977.35,1420.77 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip3601)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  212.353,1420.33 243.986,1420.33 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip3601)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  212.353,1008.6 243.986,1008.6 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip3601)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  212.353,596.879 243.986,596.879 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip3601)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  212.353,185.156 243.986,185.156 \n",
       "  \"/>\n",
       "<g clip-path=\"url(#clip3601)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:middle;\" transform=\"rotate(0, 272.039, 1494.48)\" x=\"272.039\" y=\"1494.48\">2</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip3601)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:middle;\" transform=\"rotate(0, 840.477, 1494.48)\" x=\"840.477\" y=\"1494.48\">4</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip3601)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:middle;\" transform=\"rotate(0, 1408.92, 1494.48)\" x=\"1408.92\" y=\"1494.48\">6</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip3601)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:middle;\" transform=\"rotate(0, 1977.35, 1494.48)\" x=\"1977.35\" y=\"1494.48\">8</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip3601)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:end;\" transform=\"rotate(0, 188.353, 1437.83)\" x=\"188.353\" y=\"1437.83\">-7</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip3601)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:end;\" transform=\"rotate(0, 188.353, 1026.1)\" x=\"188.353\" y=\"1026.1\">-6</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip3601)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:end;\" transform=\"rotate(0, 188.353, 614.379)\" x=\"188.353\" y=\"614.379\">-5</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip3601)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:end;\" transform=\"rotate(0, 188.353, 202.656)\" x=\"188.353\" y=\"202.656\">-4</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip3601)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:84px; text-anchor:middle;\" transform=\"rotate(0, 1266.81, 73.2)\" x=\"1266.81\" y=\"73.2\">Float64</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip3601)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:66px; text-anchor:middle;\" transform=\"rotate(0, 1266.81, 1590.4)\" x=\"1266.81\" y=\"1590.4\">log_2 N</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip3601)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:66px; text-anchor:middle;\" transform=\"rotate(-90, 57.6, 783.233)\" x=\"57.6\" y=\"783.233\">log_10 (Time/s)</text>\n",
       "</g>\n",
       "<polyline clip-path=\"url(#clip3603)\" style=\"stroke:#009af9; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  272.039,1387.5 556.258,1403.28 840.477,1281.03 1124.7,1215.18 1408.92,1006.07 1693.14,775.624 1977.35,235.595 2261.57,163.187 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip3603)\" style=\"stroke:#e26f46; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  272.039,412.054 556.258,360.185 840.477,400.372 1124.7,398.151 1408.92,327.29 1693.14,387.633 1977.35,277.498 2261.57,291.548 \n",
       "  \"/>\n",
       "<polygon clip-path=\"url(#clip3601)\" points=\"\n",
       "284.353,390.944 928.243,390.944 928.243,209.504 284.353,209.504 \n",
       "  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<polyline clip-path=\"url(#clip3601)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  284.353,390.944 928.243,390.944 928.243,209.504 284.353,209.504 284.353,390.944 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip3601)\" style=\"stroke:#009af9; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  308.353,269.984 452.353,269.984 \n",
       "  \"/>\n",
       "<g clip-path=\"url(#clip3601)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:start;\" transform=\"rotate(0, 476.353, 287.484)\" x=\"476.353\" y=\"287.484\">CPU mat_vec_mul</text>\n",
       "</g>\n",
       "<polyline clip-path=\"url(#clip3601)\" style=\"stroke:#e26f46; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  308.353,330.464 452.353,330.464 \n",
       "  \"/>\n",
       "<g clip-path=\"url(#clip3601)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:start;\" transform=\"rotate(0, 476.353, 347.964)\" x=\"476.353\" y=\"347.964\">GPU mat_vec_mul</text>\n",
       "</g>\n",
       "</svg>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cpu_times = map(i->median(benchmark_results64[i][\"cpu_mat_vec_mul\"].times),1:length(problem_sizes))\n",
    "plt = plot(log2.(problem_sizes),log10.(cpu_times*1e-9), label=\"CPU mat_vec_mul\",xaxis=\"log_2 N\", yaxis=\"log_10 (Time/s)\", title=\"Float64\", legend=:topleft)\n",
    "if haskey(benchmark_results64[1],\"gpu_mat_vec_mul\")\n",
    "    gpu_times = map(i->median(benchmark_results64[i][\"gpu_mat_vec_mul\"].times),1:length(problem_sizes))\n",
    "    plt = plot!(log2.(problem_sizes),log10.(gpu_times*1e-9), label=\"GPU mat_vec_mul\")\n",
    "end\n",
    "if haskey(benchmark_results64[1],\"cpu_mat_mat_mul\")\n",
    "    cpu_times = map(i->median(benchmark_results64[i][\"cpu_mat_mat_mul\"].times),1:length(problem_sizes))\n",
    "    plt = plot!(log2.(problem_sizes),log10.(cpu_times*1e-9), label=\"CPU mat_mat_mul\")\n",
    "end\n",
    "if haskey(benchmark_results64[1],\"gpu_mat_mat_mul\")\n",
    "    gpu_times = map(i->median(benchmark_results64[i][\"gpu_mat_mat_mul\"].times),1:length(problem_sizes))\n",
    "    plt = plot!(log2.(problem_sizes),log10.(gpu_times*1e-9), label=\"GPU mat_mat_mul\")\n",
    "end\n",
    "display(plt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implications for your class project\n",
    "Does your project involve linear algebra on large matrices/vectors?  Does it use thousands of linear algebra calculations with smaller matrices/vectors?\n",
    "If yes to either, then discuss the implications of the results from this exercise for the suitability of using GPUs to accelerate the linear algebra in your class project.  What precission would you use?\n",
    "\n",
    "**The neural network part of the program is certainly linear algebra heavy, but essentially the GPU parallelization has already been done in the Flux package. The rest of the program probably could not take advantage of GPUs for a significant speedup.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.0.2",
   "language": "julia",
   "name": "julia-1.0"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.0.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
