{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Astro 528, Lab 7, Exercise 1\n",
    "## GPU Computing I:  Getting Started & Linear Algebra\n",
    "\n",
    "In this lab exercise, we'll verify that we have access to a GPU, learn a little about its properties and benchmark some simple operations on a GPU to see how performance compares.  While most laptops have a GPU, most will either note be setup for general purpose computing or will be so low power that the benchmarking results won't be very informative.  Therefore, students are advised to run the exercises in this lab on ICS-ACI rather than their own system (unless they're confident they have setup their own system for GPU computing properly).  \n",
    "\n",
    "The ICS-ACI Jupyter notebook server and interactive desktop provided by the ICS-ACI portal are now using interactive notes that include a GPU, and students should be able to run all the code there.  However, the GPUs on the interactive nodes are relatively modest GPUs.  Therefore, after you've stepped through the notebook, you'll want to submit a PBS job, so you can run the calculations on one of the CyberLAMP GPU nodes.  For that step, you'll use the [command line interface](https://ics.psu.edu/computing-services/ics-aci-user-guide/#05-00-basics-aci-resources) to submit the PBS jobs, following a similar syntax as the [lab's 6 README](https://github.com/PsuAstro528/lab6-start/blob/master/README.md).  \n",
    "\n",
    "## Setting up Julia to use the GPU\n",
    "First, we need to make sure that your computer can find the [CUDA Toolkit](https://developer.nvidia.com/cuda-toolkit).  I've installed version 9.1.0 in `/gpfs/group/ebf11/default/astro528/cuda` and all students in the class should have read access to it.  In order for other packages to know where to find it, we'll set the environment variable `CUDAHOME`.  You could do this in a dotfile (e.g., adding \n",
    "```bash \n",
    "export CUDAHOME=/gpfs/group/ebf11/default/astro528/cuda\n",
    "```\n",
    "to your `~/.bashrc` *before* you start the Jupyter notebook server or interactive desktop file.  If that worked, then the next cell should return that path.  If it didn't work, then the `else` part of the next cell should set it for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The CUDAHOME environment variable has not been set.  Setting it now...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"/gpfs/group/ebf11/default/astro528/cuda\""
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if haskey(ENV,\"CUDAHOME\")\n",
    "    println(\"The CUDAHOME environment variable has been set to: \",ENV[\"CUDAHOME\"])\n",
    "else\n",
    "    println(\"The CUDAHOME environment variable has not been set.  Setting it now...\")\n",
    "    ENV[\"CUDAHOME\"] = \"/gpfs/group/ebf11/default/astro528/cuda\"\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, that we've told Julia were to find the CUDA toolkit, install the pacakages we'll be using, activate the current project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"/storage/home/l/len56/lab7-lenun/Project.toml\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using Pkg\n",
    "Pkg.activate(\".\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then install the necessary packages.  This instantiate should only need to be run once, assuming everything worked.  If you get errors, then you'll likely need to make sure CUDAHOME is set correctly and then use `Pkg.build` to rebuild those libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m  Updating\u001b[22m\u001b[39m registry at `~/work/julia_depot/registries/General`\n",
      "\u001b[32m\u001b[1m  Updating\u001b[22m\u001b[39m git-repo `https://github.com/JuliaRegistries/General.git`\n",
      "\u001b[2K\u001b[?25h[1mFetching:\u001b[22m\u001b[39m [========================================>]  100.0 %.0 % [=========>                               ]  20.8 %]  41.5 % [=========================>               ]  62.3 %>  ]  93.5 %"
     ]
    }
   ],
   "source": [
    "Pkg.instantiate()  # Only need to run once for the whole lab (assuming it works the first time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Don't worry if you get a warning about not finding the cudnn library.\n",
    "\n",
    "## CUDAdrv:  Julia interface to the CUDA driver\n",
    "\n",
    "For this first exercise, we'll install several packages individually to see what they do.  The [CUDAdrv.jl](https://juliagpu.gitlab.io/CUDAdrv.jl/) package is a Julia wrapper for the CUDA driver that allows programs to access an NVIDIA GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "using CUDAdrv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This provides very basic functionality, like querying what version of the CUDA Toolkit is being used,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "v\"9.1.0\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CUDAdrv.version()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "initializing the GPU, querying the name of the GPU being used,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Quadro K4000\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpu_dev = CuDevice(0)\n",
    "name(gpu_dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "querying how much RAM is avaliable on the GPU,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU has 2.94744873046875GB of RAM.\n"
     ]
    }
   ],
   "source": [
    "gpu_ram = Int64(totalmem(gpu_dev)) \n",
    "println(\"GPU has \",gpu_ram/1024^3, \"GB of RAM.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and the version indicating the current GPU's [\"compute capability\"](https://en.wikipedia.org/wiki/CUDA#GPUs_supported)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "v\"3.0.0\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "capability(gpu_dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In principle, the compute capability tells you the technical sepcifications of your GPU that would be needed to do fairly low-level programming.  Rather than [looking up the specs of your graphics card online](https://en.wikipedia.org/wiki/List_of_Nvidia_graphics_processing_units), you can query [a large list of GPU attributes](https://github.com/JuliaGPU/CUDAdrv.jl/blob/master/src/devices.jl#L60).  For example, how many multi-processors does the current GPU have?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attribute(gpu_dev,CUDAdrv.MULTIPROCESSOR_COUNT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GPUs execute many calculations at once, typically thousands or even hundreds of thousands threads are run in a single call to the GPU kernel.  The threads are grouped into \"blocks\" and the GPU can distribute different blocks to different multiprocessors as it sees fit.  Each blocks may be broken down into one or multiple \"warps\" which are run on the same multiprocessor, but not necessarily at the same time.  All computations in one warp are executed in parallel on a single multiprocessor.  Let's check the maximum number of threads per block and how many threads are in one warp on your GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1024"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attribute(gpu_dev,CUDAdrv.MAX_THREADS_PER_BLOCK)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "warpsize(gpu_dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have fewer threads in a block, than the warp size, then then some of the arithmetic units in the multiprocessor won't be used effectively.  \n",
    "Nevertheless, sometimes this is necessary, because there's a fixed number of registers per block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65536"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attribute(gpu_dev,CUDAdrv.MAX_REGISTERS_PER_BLOCK)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If one wants to get the full power of GPUs, then one is likely to do at least some low-level GPU programming in which one would need to make use of this information to choose how to divide up the work among threads and blocks efficiently.  \n",
    "\n",
    "### GPUArrays:  A High-level Julia interface to GPU programming\n",
    "\n",
    "For this exercise, we'll use the [GPUArrays.jl](https://github.com/JuliaGPU/GPUArrays.jl) package that provides a high-level interface that hides the above details from the programmer.  Different GPU manufacturers provide different functionality and libraries.  The GPUs at ICS-ACI are NVIDIA GPUs, and these are most efficiently programmed using [CUDA](https://en.wikipedia.org/wiki/CUDA).  On the other hand, AMD GPUs are most efficiently programmed using [OpenCL](https://en.wikipedia.org/wiki/OpenCL).  Some programmers perfer to use OpenCL, since CUDA is a proprietary language.  Julia has mid/high-level libraries for array operations for using either CUDA (i.e., [CuArrays.jl](https://github.com/JuliaGPU/CuArrays.jl)) or OpenCL (i.e., [CLArrays.jl](https://github.com/JuliaGPU/CLArrays.jl)).  It would be nice to be able to write code that can run with either type of GPU.  Indeed, the [GPUArrays.jl](https://github.com/JuliaGPU/GPUArrays.jl) package provides just that.  For many applications, [GPUArrays.jl](https://github.com/JuliaGPU/GPUArrays.jl) provides all you need to get orders of magnitude speed-up relative to a CPU.  \n",
    "\n",
    "Since this is our first time using these packages, let's load them one at a time, just in case there are any error messages.  Since CuArrays is the lower-level package, let's first make sure that load successfully."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "using CuArrays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assuming that CuArrays loaded successfuly, proceed to load the GPUArrays package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "using GPUArrays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we'll benchmark some linear algebra.  Because linear algebra is so common, there are efficient [BLAS libraries](https://en.wikipedia.org/wiki/Basic_Linear_Algebra_Subprograms) avaliable for both CPUs and GPU.\n",
    "Create some matrices and arrays for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "N = 1024\n",
    "A_h = randn(N,N)\n",
    "x_h = randn(N);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "b_h = A_h*x_h;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To perform calculations on a GPU, we'll need to send the data from the CPU to the GPU.  The CuArrays pacakge provides a datatype `CuDeviceArray` for arrays that live on the device.  Manually specifying when to send data back and forth can be good for efficiency, but does require more care.  So instead, we use `CuArray`'s that take care of moving the data between the CPU (or \"host\") memory system and the GPU (or \"device\") memory system for us.  \n",
    "\n",
    "We can create a 'CuArray' from an existing Array simply with the `cu(.)` function.  Then we can proceed to do arithmetic on them with the same syntax as when using standard Arrays.  (Generic programming is amazing!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1024-element CuArray{Float32,1}:\n",
       " -16.373007 \n",
       " -69.3542   \n",
       " -45.514687 \n",
       "  29.823957 \n",
       " -23.366787 \n",
       "  34.24115  \n",
       "  22.392832 \n",
       "   5.1128287\n",
       " -49.474075 \n",
       "  14.356754 \n",
       "  34.723778 \n",
       "  10.882039 \n",
       "  26.835499 \n",
       "   ⋮        \n",
       " -63.903084 \n",
       "  15.731693 \n",
       "   7.5420556\n",
       "   7.469841 \n",
       " -38.40851  \n",
       " -19.607147 \n",
       "  -7.281605 \n",
       " -30.536297 \n",
       "  40.734337 \n",
       " -53.449696 \n",
       " -45.643173 \n",
       "  19.596777 "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A_d = cu(A_h)\n",
    "x_d = cu(x_h)\n",
    "b_d = A_d*x_d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, note the type of each variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(CuArray{Float32,2}, CuArray{Float32,1}, CuArray{Float32,1})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "typeof(A_d), typeof(x_d), typeof(b_d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By using a CuArray, the result calculation is also stored as a CuArray and left on the GPU.  While CuArrays let us access individual elements, if we want to look at the whole array, then it would be faster to copy all the data at once to CPU.  We can bring the full result back to the host, using `Array(.)` or `collect(.)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1024-element Array{Float32,1}:\n",
       " -16.373007 \n",
       " -69.3542   \n",
       " -45.514687 \n",
       "  29.823957 \n",
       " -23.366787 \n",
       "  34.24115  \n",
       "  22.392832 \n",
       "   5.1128287\n",
       " -49.474075 \n",
       "  14.356754 \n",
       "  34.723778 \n",
       "  10.882039 \n",
       "  26.835499 \n",
       "   ⋮        \n",
       " -63.903084 \n",
       "  15.731693 \n",
       "   7.5420556\n",
       "   7.469841 \n",
       " -38.40851  \n",
       " -19.607147 \n",
       "  -7.281605 \n",
       " -30.536297 \n",
       "  40.734337 \n",
       " -53.449696 \n",
       " -45.643173 \n",
       "  19.596777 "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b_comp_h = Array(b_d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll compare the results.  What do you expect for the maximum difference in any element in `b`?\n",
    "        \n",
    "INSERT RESPONSE **The difference will be very small. Probably as small as 1e-10 or something.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0657913069044298e-5"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maximum(b_comp_h .- b_h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How did the results compare to your expectations?  \n",
    "\n",
    "INSERT RESPONSE **2e-5, not quite as small as I thought, but still pretty small.**\n",
    "\n",
    "One thing to keep in mind is that most \"consumer grade\" GPUs are designed to only perform single-precision arithmetic.  Even GPUs that do support double precission are often significantly slower at double precission arithmetic than single precission.  The difference is particularly noticable for \"consumer grade\" GPUs.  When we need double precission, we can specify that explicitly.  Below we will use double precision on the GPU and test its accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.7053025658242404e-13"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A_d64 = CuArray{Float64}(A_h)\n",
    "x_d64 = CuArray{Float64}(x_h)\n",
    "b_d64 = A_d64*x_d64\n",
    "maximum(Array(b_d64) .- b_h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, how do the results compare to your expectations?  \n",
    "\n",
    "RESPONSE: **Given the previous small value, I expect double precision to lead to even small results. Which it did: 1.7e-13.**\n",
    "\n",
    "\n",
    "## Benchmarking GPU for Linear Algebra\n",
    "Now, we'll do some benchmarking of the CPU vs GPU, so let's load the usual BenchmarkTools package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "using BenchmarkTools, Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we'll be able to use the exact same macros to benchmark code running on either the CPU or the GPU.  To keep things reasonably fast, we'll specify that we only want Julia to benchmark each calculation a few times.  \n",
    "Calls to the GPU run asynchronously.  So if we want to benchmark how long is required to the calculation to complete, we need to tell Julia to wait until the calculation has been synchronized.  We can do that either with the `@sync` macro in CuArrays or with the `synchronize(.)` function in GPUArrays to make our code more general.  `@sync` makes everyone wait until everything is complete.  `synchronize(x)` only waits until the array `x` is synchronized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  memory estimate:  592 bytes\n",
       "  allocs estimate:  22\n",
       "  --------------\n",
       "  minimum time:     10.074 μs (0.00% GC)\n",
       "  median time:      14.820 μs (0.00% GC)\n",
       "  mean time:        23.695 μs (0.00% GC)\n",
       "  maximum time:     68.168 μs (0.00% GC)\n",
       "  --------------\n",
       "  samples:          5\n",
       "  evals/sample:     1"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@benchmark b_d = $A_d*$x_d samples=5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How long does it take to launch the GPU kernel and exit?\n",
    "\n",
    "INSERT RESPONSE **The median is $14.8 \\times 10^{-6}$ seconds.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  memory estimate:  704 bytes\n",
       "  allocs estimate:  26\n",
       "  --------------\n",
       "  minimum time:     106.291 μs (0.00% GC)\n",
       "  median time:      121.048 μs (0.00% GC)\n",
       "  mean time:        318.756 μs (0.00% GC)\n",
       "  maximum time:     1.036 ms (0.00% GC)\n",
       "  --------------\n",
       "  samples:          5\n",
       "  evals/sample:     1"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@benchmark CuArrays.@sync( b_d = $A_d*$x_d) samples=5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How long did it take to complete the calculation and store to to an array on the GPU?  How does this compare to the cost of launching the kernel?  What are the implications for the ammount of work you'd want per GPU call in order to make efficient use of the GPU?\n",
    "\n",
    "INSERT RESPONSE **The median runtime is $121\\times 10^{-6}$ seconds. The launch time is about 10% of the runtime. Ideally, you want to avoid being bottlenecked by the launch time. If you are going to use GPU, then the amount of work should yield a large runtime compared to the launch. Otherwise, it may be better to use CPU.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  memory estimate:  2.16 KiB\n",
       "  allocs estimate:  62\n",
       "  --------------\n",
       "  minimum time:     80.203 μs (0.00% GC)\n",
       "  median time:      83.581 μs (0.00% GC)\n",
       "  mean time:        94.570 μs (0.00% GC)\n",
       "  maximum time:     141.618 μs (0.00% GC)\n",
       "  --------------\n",
       "  samples:          5\n",
       "  evals/sample:     1"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@benchmark ( b_d .= $A_d*$x_d;  GPUArrays.synchronize(b_d); ) samples=5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can compare that to double precission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: \n",
       "  memory estimate:  2.16 KiB\n",
       "  allocs estimate:  62\n",
       "  --------------\n",
       "  minimum time:     129.604 μs (0.00% GC)\n",
       "  median time:      135.542 μs (0.00% GC)\n",
       "  mean time:        149.356 μs (0.00% GC)\n",
       "  maximum time:     206.624 μs (0.00% GC)\n",
       "  --------------\n",
       "  samples:          5\n",
       "  evals/sample:     1"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@benchmark ( b_d64 .= $A_d64*$x_d64;  GPUArrays.synchronize(b_d64); ) samples=5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we'll want to perform benchmarks for several problem sizes, I've provided a function `run_benchmarks` to make things a little easier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "run_benchmarks"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" run_benchmarks(N; opts)\n",
    "Benchmark matrix-vector multiplication and optionally linear solve.\n",
    "Optional arguments:\n",
    "- num_samples:  How many times to perform each calculation being benchmarked\n",
    "- calc_solve: Whether to benchmark linear solve (false)\n",
    "- run_cpu:  Whether to perform benchmarks on cpu (true)\n",
    "- run_gpu:  Whether to perform benchmarks on gpu (false)\n",
    "- verbose:  Whether to print status updates.\n",
    "Output: A dictionary with results of each benchmark performed and \n",
    "        optionally the difference in final CPU and GPU calculations (if both are run).  \n",
    "\"\"\"\n",
    "function run_benchmarks(N::Integer; num_samples=3, run_cpu=true, run_gpu=false,\n",
    "                            gpu_type = Float32, mat_vec=true, mat_mat=false, compare=false, verbose=false )\n",
    "   verbose && println(\"Benchmarking with problem size = \",N)\n",
    "   A_h = randn(N,N)\n",
    "   x_h = randn(N)\n",
    "   output = Dict()\n",
    "   if run_gpu\n",
    "      A_d = CuArray{gpu_type}(A_h)\n",
    "      x_d = CuArray{gpu_type}(x_h)\n",
    "   end\n",
    "   if mat_vec\n",
    "      if run_cpu\n",
    "         verbose && println(\"Benchmarking matrix-vector multiply on CPU\")\n",
    "         # The `$` signs below specify that we want benchmark to use the local variables, rather than global variables with same name\n",
    "         output[\"cpu_mat_vec_mul\"] = @benchmark b_h = $A_h*$x_h samples=num_samples\n",
    "      end\n",
    "      if run_gpu\n",
    "         verbose && println(\"Benchmarking matrix-vector multiply on GPU\")\n",
    "         #output[\"gpu_mat_vec_mul\"] = @benchmark CuArrays.@sync( b_d = $A_d*$x_d) samples=num_samples\n",
    "         output[\"gpu_mat_vec_mul\"] = @benchmark ( b_d = $A_d*$x_d; GPUArrays.synchronize(b_d) ) samples=num_samples\n",
    "      end\n",
    "      if run_cpu && run_gpu && compare\n",
    "        b_h = A_h*x_h\n",
    "        b_d = A_d*x_d\n",
    "        output[\"diff_mat_vec_mul\"] = convert(typeof(b_h),Array(b_d)).-b_h\n",
    "      end\n",
    "   end\n",
    "   if mat_mat\n",
    "      if run_cpu\n",
    "         verbose && println(\"Benchmarking matrix-matrix multiply on CPU\")\n",
    "         # The `$` signs below specify that we want benchmark to use the local variables, rather than global variables with same name\n",
    "         output[\"cpu_mat_mat_mul\"] = @benchmark Asq_h = $A_h*$A_h' samples=num_samples\n",
    "      end\n",
    "      if run_gpu\n",
    "         verbose && println(\"Benchmarking matrix-matrix multiply on GPU\")\n",
    "         output[\"gpu_mat_mat_mul\"] = @benchmark ( Asq_d = $A_d*$A_d'; GPUArrays.synchronize(Asq_d) ) samples=num_samples\n",
    "      end\n",
    "      if run_cpu && run_gpu && compare\n",
    "        Asq_h = A_h*A_h'\n",
    "        Asq_d = A_d*A_d'\n",
    "        output[\"diff_mat_mat_mul\"] = convert(typeof(Asq_h),Array(Asq_d)).-Asq_h\n",
    "      end\n",
    "   end\n",
    "   return output\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, do a quick test to see how it works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Benchmarking with problem size = 128\n",
      "Benchmarking matrix-vector multiply on CPU\n",
      "Benchmarking matrix-vector multiply on GPU\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dict{Any,Any} with 3 entries:\n",
       "  \"diff_mat_vec_mul\" => [4.84277e-7, -7.25727e-7, -1.16475e-6, -1.35444e-6, -1.…\n",
       "  \"gpu_mat_vec_mul\"  => Trial(26.341 μs)\n",
       "  \"cpu_mat_vec_mul\"  => Trial(3.199 μs)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "have_gpu = @isdefined GPUArrays\n",
    "benchmark_result = run_benchmarks(128,verbose=true,mat_vec=true,run_gpu=have_gpu,compare=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll extract the median run time for the multiplication using the CPU with expressions like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3250.777777777778"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "median(benchmark_result[\"cpu_mat_vec_mul\"].times)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And compare this to the performance using double precission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Benchmarking with problem size = 128\n",
      "Benchmarking matrix-vector multiply on CPU\n",
      "Benchmarking matrix-vector multiply on GPU\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3180.3333333333335"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "have_gpu = @isdefined GPUArrays\n",
    "benchmark_result = run_benchmarks(128,verbose=true,gpu_type=Float64,mat_vec=true,run_gpu=have_gpu,compare=true)\n",
    "median(benchmark_result[\"cpu_mat_vec_mul\"].times)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's perform run some benchmarks and plot the results.  After you've made your first plot, you may want to increase the range of problem sizes slightly to extend your plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "using Plots\n",
    "#pyplot()  # in case gr() gives you trouble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11-element Array{Dict{Any,Any},1}:\n",
       " Dict(\"cpu_mat_mat_mul\"=>Trial(283.992 ns),\"gpu_mat_mat_mul\"=>Trial(24.724 μs),\"gpu_mat_vec_mul\"=>Trial(25.504 μs),\"cpu_mat_vec_mul\"=>Trial(108.213 ns))\n",
       " Dict(\"cpu_mat_mat_mul\"=>Trial(744.175 ns),\"gpu_mat_mat_mul\"=>Trial(23.881 μs),\"gpu_mat_vec_mul\"=>Trial(24.882 μs),\"cpu_mat_vec_mul\"=>Trial(102.401 ns))\n",
       " Dict(\"cpu_mat_mat_mul\"=>Trial(2.572 μs),\"gpu_mat_mat_mul\"=>Trial(24.296 μs),\"gpu_mat_vec_mul\"=>Trial(25.028 μs),\"cpu_mat_vec_mul\"=>Trial(203.106 ns))  \n",
       " Dict(\"cpu_mat_mat_mul\"=>Trial(6.144 μs),\"gpu_mat_mat_mul\"=>Trial(27.024 μs),\"gpu_mat_vec_mul\"=>Trial(26.893 μs),\"cpu_mat_vec_mul\"=>Trial(282.471 ns))  \n",
       " Dict(\"cpu_mat_mat_mul\"=>Trial(25.348 μs),\"gpu_mat_mat_mul\"=>Trial(35.182 μs),\"gpu_mat_vec_mul\"=>Trial(24.810 μs),\"cpu_mat_vec_mul\"=>Trial(1.184 μs))   \n",
       " Dict(\"cpu_mat_mat_mul\"=>Trial(137.355 μs),\"gpu_mat_mat_mul\"=>Trial(75.061 μs),\"gpu_mat_vec_mul\"=>Trial(26.374 μs),\"cpu_mat_vec_mul\"=>Trial(3.145 μs))  \n",
       " Dict(\"cpu_mat_mat_mul\"=>Trial(884.627 μs),\"gpu_mat_mat_mul\"=>Trial(103.668 μs),\"gpu_mat_vec_mul\"=>Trial(43.583 μs),\"cpu_mat_vec_mul\"=>Trial(19.032 μs))\n",
       " Dict(\"cpu_mat_mat_mul\"=>Trial(6.010 ms),\"gpu_mat_mat_mul\"=>Trial(497.855 μs),\"gpu_mat_vec_mul\"=>Trial(43.832 μs),\"cpu_mat_vec_mul\"=>Trial(61.402 μs))  \n",
       " Dict(\"cpu_mat_mat_mul\"=>Trial(47.050 ms),\"gpu_mat_mat_mul\"=>Trial(3.524 ms),\"gpu_mat_vec_mul\"=>Trial(76.513 μs),\"cpu_mat_vec_mul\"=>Trial(263.639 μs))  \n",
       " Dict(\"cpu_mat_mat_mul\"=>Trial(372.855 ms),\"gpu_mat_mat_mul\"=>Trial(27.193 ms),\"gpu_mat_vec_mul\"=>Trial(232.915 μs),\"cpu_mat_vec_mul\"=>Trial(3.132 ms)) \n",
       " Dict(\"cpu_mat_mat_mul\"=>Trial(2.865 s),\"gpu_mat_mat_mul\"=>Trial(214.444 ms),\"gpu_mat_vec_mul\"=>Trial(877.821 μs),\"cpu_mat_vec_mul\"=>Trial(16.231 ms))  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "problem_sizes = [2^i for i in 2:12]\n",
    "benchmark_results32 = map( s->run_benchmarks(s,mat_mat=true,run_gpu=have_gpu,gpu_type=Float32), problem_sizes )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"utf-8\"?>\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"600\" height=\"400\" viewBox=\"0 0 2400 1600\">\n",
       "<defs>\n",
       "  <clipPath id=\"clip4600\">\n",
       "    <rect x=\"0\" y=\"0\" width=\"2000\" height=\"2000\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<defs>\n",
       "  <clipPath id=\"clip4601\">\n",
       "    <rect x=\"0\" y=\"0\" width=\"2400\" height=\"1600\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<polygon clip-path=\"url(#clip4601)\" points=\"\n",
       "0,1600 2400,1600 2400,0 0,0 \n",
       "  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<defs>\n",
       "  <clipPath id=\"clip4602\">\n",
       "    <rect x=\"480\" y=\"0\" width=\"1681\" height=\"1600\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<polygon clip-path=\"url(#clip4601)\" points=\"\n",
       "212.353,1440.48 2321.26,1440.48 2321.26,125.984 212.353,125.984 \n",
       "  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<defs>\n",
       "  <clipPath id=\"clip4603\">\n",
       "    <rect x=\"212\" y=\"125\" width=\"2110\" height=\"1315\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<polyline clip-path=\"url(#clip4603)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  371.516,1440.48 371.516,125.984 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip4603)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  868.899,1440.48 868.899,125.984 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip4603)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  1366.28,1440.48 1366.28,125.984 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip4603)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  1863.67,1440.48 1863.67,125.984 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip4603)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  212.353,1240.93 2321.26,1240.93 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip4603)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  212.353,907.151 2321.26,907.151 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip4603)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  212.353,573.368 2321.26,573.368 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip4603)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  212.353,239.586 2321.26,239.586 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip4601)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  212.353,1440.48 2321.26,1440.48 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip4601)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  212.353,1440.48 212.353,125.984 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip4601)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  371.516,1440.48 371.516,1420.77 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip4601)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  868.899,1440.48 868.899,1420.77 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip4601)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1366.28,1440.48 1366.28,1420.77 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip4601)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1863.67,1440.48 1863.67,1420.77 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip4601)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  212.353,1240.93 243.986,1240.93 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip4601)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  212.353,907.151 243.986,907.151 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip4601)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  212.353,573.368 243.986,573.368 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip4601)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  212.353,239.586 243.986,239.586 \n",
       "  \"/>\n",
       "<g clip-path=\"url(#clip4601)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:middle;\" transform=\"rotate(0, 371.516, 1494.48)\" x=\"371.516\" y=\"1494.48\">2.5</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip4601)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:middle;\" transform=\"rotate(0, 868.899, 1494.48)\" x=\"868.899\" y=\"1494.48\">5.0</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip4601)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:middle;\" transform=\"rotate(0, 1366.28, 1494.48)\" x=\"1366.28\" y=\"1494.48\">7.5</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip4601)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:middle;\" transform=\"rotate(0, 1863.67, 1494.48)\" x=\"1863.67\" y=\"1494.48\">10.0</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip4601)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:end;\" transform=\"rotate(0, 188.353, 1258.43)\" x=\"188.353\" y=\"1258.43\">-6</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip4601)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:end;\" transform=\"rotate(0, 188.353, 924.651)\" x=\"188.353\" y=\"924.651\">-4</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip4601)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:end;\" transform=\"rotate(0, 188.353, 590.868)\" x=\"188.353\" y=\"590.868\">-2</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip4601)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:end;\" transform=\"rotate(0, 188.353, 257.086)\" x=\"188.353\" y=\"257.086\">0</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip4601)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:84px; text-anchor:middle;\" transform=\"rotate(0, 1266.81, 73.2)\" x=\"1266.81\" y=\"73.2\">Float32</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip4601)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:66px; text-anchor:middle;\" transform=\"rotate(0, 1266.81, 1590.4)\" x=\"1266.81\" y=\"1590.4\">log_2 N</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip4601)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:66px; text-anchor:middle;\" transform=\"rotate(-90, 57.6, 783.233)\" x=\"57.6\" y=\"783.233\">log_10 (Time/s)</text>\n",
       "</g>\n",
       "<polyline clip-path=\"url(#clip4603)\" style=\"stroke:#009af9; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  272.039,1392.35 470.992,1403.28 669.946,1348.79 868.899,1331.64 1067.85,1222.64 1266.81,1153.23 1465.76,1024.09 1664.71,874.871 1863.67,832.553 2062.62,652.102 \n",
       "  2261.57,538.018 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip4603)\" style=\"stroke:#e26f46; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  272.039,1002.91 470.992,999.025 669.946,999.898 868.899,1000.91 1067.85,1003.49 1266.81,999.09 1465.76,964.146 1664.71,965.218 1863.67,924.979 2062.62,844.472 \n",
       "  2261.57,749.642 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip4603)\" style=\"stroke:#3da44d; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  272.039,1321.6 470.992,1261.55 669.946,1168.29 868.899,1097.09 1067.85,1003.49 1266.81,883.855 1465.76,746.457 1664.71,610.259 1863.67,460.816 2062.62,310.928 \n",
       "  2261.57,163.187 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip4603)\" style=\"stroke:#c271d2; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  272.039,996.51 470.992,998.73 669.946,1002.4 868.899,996.934 1067.85,981.717 1266.81,925.343 1465.76,863.675 1664.71,790.053 1863.67,648.953 2062.62,500.819 \n",
       "  2261.57,351.157 \n",
       "  \"/>\n",
       "<polygon clip-path=\"url(#clip4601)\" points=\"\n",
       "284.353,511.904 933.585,511.904 933.585,209.504 284.353,209.504 \n",
       "  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<polyline clip-path=\"url(#clip4601)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  284.353,511.904 933.585,511.904 933.585,209.504 284.353,209.504 284.353,511.904 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip4601)\" style=\"stroke:#009af9; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  308.353,269.984 452.353,269.984 \n",
       "  \"/>\n",
       "<g clip-path=\"url(#clip4601)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:start;\" transform=\"rotate(0, 476.353, 287.484)\" x=\"476.353\" y=\"287.484\">CPU mat_vec_mul</text>\n",
       "</g>\n",
       "<polyline clip-path=\"url(#clip4601)\" style=\"stroke:#e26f46; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  308.353,330.464 452.353,330.464 \n",
       "  \"/>\n",
       "<g clip-path=\"url(#clip4601)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:start;\" transform=\"rotate(0, 476.353, 347.964)\" x=\"476.353\" y=\"347.964\">GPU mat_vec_mul</text>\n",
       "</g>\n",
       "<polyline clip-path=\"url(#clip4601)\" style=\"stroke:#3da44d; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  308.353,390.944 452.353,390.944 \n",
       "  \"/>\n",
       "<g clip-path=\"url(#clip4601)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:start;\" transform=\"rotate(0, 476.353, 408.444)\" x=\"476.353\" y=\"408.444\">CPU mat_mat_mul</text>\n",
       "</g>\n",
       "<polyline clip-path=\"url(#clip4601)\" style=\"stroke:#c271d2; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  308.353,451.424 452.353,451.424 \n",
       "  \"/>\n",
       "<g clip-path=\"url(#clip4601)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:start;\" transform=\"rotate(0, 476.353, 468.924)\" x=\"476.353\" y=\"468.924\">GPU mat_mat_mul</text>\n",
       "</g>\n",
       "</svg>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cpu_times = map(i->median(benchmark_results32[i][\"cpu_mat_vec_mul\"].times),1:length(problem_sizes))\n",
    "plt = plot(log2.(problem_sizes),log10.(cpu_times*1e-9), label=\"CPU mat_vec_mul\",xaxis=\"log_2 N\", yaxis=\"log_10 (Time/s)\", title=\"Float32\", legend=:topleft)\n",
    "if haskey(benchmark_results32[1],\"gpu_mat_vec_mul\")\n",
    "    gpu_times = map(i->median(benchmark_results32[i][\"gpu_mat_vec_mul\"].times),1:length(problem_sizes))\n",
    "    plt = plot!(log2.(problem_sizes),log10.(gpu_times*1e-9), label=\"GPU mat_vec_mul\")\n",
    "end\n",
    "if haskey(benchmark_results32[1],\"cpu_mat_mat_mul\")\n",
    "    cpu_times = map(i->median(benchmark_results32[i][\"cpu_mat_mat_mul\"].times),1:length(problem_sizes))\n",
    "    plt = plot!(log2.(problem_sizes),log10.(cpu_times*1e-9), label=\"CPU mat_mat_mul\")\n",
    "end\n",
    "if haskey(benchmark_results32[1],\"gpu_mat_mat_mul\")\n",
    "    gpu_times = map(i->median(benchmark_results32[i][\"gpu_mat_mat_mul\"].times),1:length(problem_sizes))\n",
    "    plt = plot!(log2.(problem_sizes),log10.(gpu_times*1e-9), label=\"GPU mat_mat_mul\")\n",
    "end\n",
    "display(plt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8-element Array{Dict{Any,Any},1}:\n",
       " Dict(\"gpu_mat_vec_mul\"=>Trial(25.229 μs),\"cpu_mat_vec_mul\"=>Trial(106.403 ns))\n",
       " Dict(\"gpu_mat_vec_mul\"=>Trial(25.225 μs),\"cpu_mat_vec_mul\"=>Trial(103.414 ns))\n",
       " Dict(\"gpu_mat_vec_mul\"=>Trial(24.862 μs),\"cpu_mat_vec_mul\"=>Trial(145.554 ns))\n",
       " Dict(\"gpu_mat_vec_mul\"=>Trial(26.397 μs),\"cpu_mat_vec_mul\"=>Trial(283.375 ns))\n",
       " Dict(\"gpu_mat_vec_mul\"=>Trial(26.241 μs),\"cpu_mat_vec_mul\"=>Trial(868.178 ns))\n",
       " Dict(\"gpu_mat_vec_mul\"=>Trial(27.485 μs),\"cpu_mat_vec_mul\"=>Trial(3.131 μs))  \n",
       " Dict(\"gpu_mat_vec_mul\"=>Trial(49.443 μs),\"cpu_mat_vec_mul\"=>Trial(26.421 μs)) \n",
       " Dict(\"gpu_mat_vec_mul\"=>Trial(55.107 μs),\"cpu_mat_vec_mul\"=>Trial(76.400 μs)) "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "problem_sizes = [2^i for i in 2:9]\n",
    "benchmark_results64 = map( s->run_benchmarks(s,mat_mat=false,run_gpu=have_gpu,gpu_type=Float64), problem_sizes )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"utf-8\"?>\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"600\" height=\"400\" viewBox=\"0 0 2400 1600\">\n",
       "<defs>\n",
       "  <clipPath id=\"clip4800\">\n",
       "    <rect x=\"0\" y=\"0\" width=\"2000\" height=\"2000\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<defs>\n",
       "  <clipPath id=\"clip4801\">\n",
       "    <rect x=\"0\" y=\"0\" width=\"2400\" height=\"1600\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<polygon clip-path=\"url(#clip4801)\" points=\"\n",
       "0,1600 2400,1600 2400,0 0,0 \n",
       "  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<defs>\n",
       "  <clipPath id=\"clip4802\">\n",
       "    <rect x=\"480\" y=\"0\" width=\"1681\" height=\"1600\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<polygon clip-path=\"url(#clip4801)\" points=\"\n",
       "212.353,1440.48 2321.26,1440.48 2321.26,125.984 212.353,125.984 \n",
       "  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<defs>\n",
       "  <clipPath id=\"clip4803\">\n",
       "    <rect x=\"212\" y=\"125\" width=\"2110\" height=\"1315\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<polyline clip-path=\"url(#clip4803)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  272.039,1440.48 272.039,125.984 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip4803)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  840.477,1440.48 840.477,125.984 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip4803)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  1408.92,1440.48 1408.92,125.984 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip4803)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  1977.35,1440.48 1977.35,125.984 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip4803)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  212.353,1429.45 2321.26,1429.45 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip4803)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  212.353,1010.18 2321.26,1010.18 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip4803)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  212.353,590.905 2321.26,590.905 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip4803)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  212.353,171.63 2321.26,171.63 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip4801)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  212.353,1440.48 2321.26,1440.48 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip4801)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  212.353,1440.48 212.353,125.984 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip4801)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  272.039,1440.48 272.039,1420.77 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip4801)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  840.477,1440.48 840.477,1420.77 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip4801)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1408.92,1440.48 1408.92,1420.77 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip4801)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1977.35,1440.48 1977.35,1420.77 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip4801)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  212.353,1429.45 243.986,1429.45 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip4801)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  212.353,1010.18 243.986,1010.18 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip4801)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  212.353,590.905 243.986,590.905 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip4801)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  212.353,171.63 243.986,171.63 \n",
       "  \"/>\n",
       "<g clip-path=\"url(#clip4801)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:middle;\" transform=\"rotate(0, 272.039, 1494.48)\" x=\"272.039\" y=\"1494.48\">2</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip4801)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:middle;\" transform=\"rotate(0, 840.477, 1494.48)\" x=\"840.477\" y=\"1494.48\">4</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip4801)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:middle;\" transform=\"rotate(0, 1408.92, 1494.48)\" x=\"1408.92\" y=\"1494.48\">6</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip4801)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:middle;\" transform=\"rotate(0, 1977.35, 1494.48)\" x=\"1977.35\" y=\"1494.48\">8</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip4801)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:end;\" transform=\"rotate(0, 188.353, 1446.95)\" x=\"188.353\" y=\"1446.95\">-7</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip4801)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:end;\" transform=\"rotate(0, 188.353, 1027.68)\" x=\"188.353\" y=\"1027.68\">-6</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip4801)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:end;\" transform=\"rotate(0, 188.353, 608.405)\" x=\"188.353\" y=\"608.405\">-5</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip4801)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:end;\" transform=\"rotate(0, 188.353, 189.13)\" x=\"188.353\" y=\"189.13\">-4</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip4801)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:84px; text-anchor:middle;\" transform=\"rotate(0, 1266.81, 73.2)\" x=\"1266.81\" y=\"73.2\">Float64</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip4801)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:66px; text-anchor:middle;\" transform=\"rotate(0, 1266.81, 1590.4)\" x=\"1266.81\" y=\"1590.4\">log_2 N</text>\n",
       "</g>\n",
       "<g clip-path=\"url(#clip4801)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:66px; text-anchor:middle;\" transform=\"rotate(-90, 57.6, 783.233)\" x=\"57.6\" y=\"783.233\">log_10 (Time/s)</text>\n",
       "</g>\n",
       "<polyline clip-path=\"url(#clip4803)\" style=\"stroke:#009af9; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  272.039,1365.73 556.258,1403.28 840.477,1340.44 1124.7,1237.13 1408.92,1034.26 1693.14,798.661 1977.35,355.589 2261.57,163.187 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip4803)\" style=\"stroke:#e26f46; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  272.039,413.93 556.258,409.305 840.477,406.836 1124.7,395.383 1408.92,407.115 1693.14,393.686 1977.35,228.345 2261.57,274.417 \n",
       "  \"/>\n",
       "<polygon clip-path=\"url(#clip4801)\" points=\"\n",
       "284.353,390.944 928.243,390.944 928.243,209.504 284.353,209.504 \n",
       "  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<polyline clip-path=\"url(#clip4801)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  284.353,390.944 928.243,390.944 928.243,209.504 284.353,209.504 284.353,390.944 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip4801)\" style=\"stroke:#009af9; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  308.353,269.984 452.353,269.984 \n",
       "  \"/>\n",
       "<g clip-path=\"url(#clip4801)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:start;\" transform=\"rotate(0, 476.353, 287.484)\" x=\"476.353\" y=\"287.484\">CPU mat_vec_mul</text>\n",
       "</g>\n",
       "<polyline clip-path=\"url(#clip4801)\" style=\"stroke:#e26f46; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  308.353,330.464 452.353,330.464 \n",
       "  \"/>\n",
       "<g clip-path=\"url(#clip4801)\">\n",
       "<text style=\"fill:#000000; fill-opacity:1; font-family:Arial,Helvetica Neue,Helvetica,sans-serif; font-size:48px; text-anchor:start;\" transform=\"rotate(0, 476.353, 347.964)\" x=\"476.353\" y=\"347.964\">GPU mat_vec_mul</text>\n",
       "</g>\n",
       "</svg>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cpu_times = map(i->median(benchmark_results64[i][\"cpu_mat_vec_mul\"].times),1:length(problem_sizes))\n",
    "plt = plot(log2.(problem_sizes),log10.(cpu_times*1e-9), label=\"CPU mat_vec_mul\",xaxis=\"log_2 N\", yaxis=\"log_10 (Time/s)\", title=\"Float64\", legend=:topleft)\n",
    "if haskey(benchmark_results64[1],\"gpu_mat_vec_mul\")\n",
    "    gpu_times = map(i->median(benchmark_results64[i][\"gpu_mat_vec_mul\"].times),1:length(problem_sizes))\n",
    "    plt = plot!(log2.(problem_sizes),log10.(gpu_times*1e-9), label=\"GPU mat_vec_mul\")\n",
    "end\n",
    "if haskey(benchmark_results64[1],\"cpu_mat_mat_mul\")\n",
    "    cpu_times = map(i->median(benchmark_results64[i][\"cpu_mat_mat_mul\"].times),1:length(problem_sizes))\n",
    "    plt = plot!(log2.(problem_sizes),log10.(cpu_times*1e-9), label=\"CPU mat_mat_mul\")\n",
    "end\n",
    "if haskey(benchmark_results64[1],\"gpu_mat_mat_mul\")\n",
    "    gpu_times = map(i->median(benchmark_results64[i][\"gpu_mat_mat_mul\"].times),1:length(problem_sizes))\n",
    "    plt = plot!(log2.(problem_sizes),log10.(gpu_times*1e-9), label=\"GPU mat_mat_mul\")\n",
    "end\n",
    "display(plt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implications for your class project\n",
    "Does your project involve linear algebra on large matrices/vectors?  Does it use thousands of linear algebra calculations with smaller matrices/vectors?\n",
    "If yes to either, then discuss the implications of the results from this exercise for the suitability of using GPUs to accelerate the linear algebra in your class project.  What precission would you use?\n",
    "\n",
    "INSERT RESPONSE **Currently my project does not involve linear algebra. But I can image that I could incorporate ways to do thousands of calculations. I would use double precision in order to increase the accuracy.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.0.2",
   "language": "julia",
   "name": "julia-1.0"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.0.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
